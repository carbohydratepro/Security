{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0waGl4Y2MpD"
      },
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWaMAVr--mVi"
      },
      "source": [
        "### Copycat CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmXO6_eV2Oqs"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# ラッパーおよびユーティリティをインポートする\n",
        "from art.estimators.classification.keras import KerasClassifier\n",
        "from art.utils import load_mnist\n",
        "\n",
        "# MNISTデータセットをロードする\n",
        "(X_train, y_train), (X_test, y_test), \\\n",
        "    min_pixel_value, max_pixel_value = load_mnist()\n",
        "\n",
        "nb_classes=10\n",
        "\n",
        "# 攻撃対象のモデルを定義する\n",
        "model = Sequential()\n",
        "model.add(Conv2D(1,kernel_size=(7, 7), activation='relu', \n",
        "                 input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(nb_classes, activation='softmax'))\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(learning_rate=0.01),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "victim_classifier = KerasClassifier(model,\n",
        "                                    clip_values=(0, 1), \n",
        "                                    use_logits=False)\n",
        "victim_classifier.fit(X_train, y_train, nb_epochs=5, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQbWB02u2TJ2"
      },
      "source": [
        "# 窃取先のモデルの雛形を定義する\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', \n",
        "                 input_shape=(28, 28, 1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(nb_classes, activation='softmax'))\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(learning_rate=0.01),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "thieved_classifier = KerasClassifier(model,\n",
        "                                     clip_values=(0, 1), \n",
        "                                     use_logits=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYOGwqvN2fYk"
      },
      "source": [
        "# 攻撃手法をインポートする\n",
        "from art.attacks.extraction.copycat_cnn import CopycatCNN\n",
        "\n",
        "attack = CopycatCNN(classifier=victim_classifier,\n",
        "                    batch_size_fit=16,\n",
        "                    batch_size_query=16,\n",
        "                    nb_epochs=10,\n",
        "                    nb_stolen=1000)\n",
        "\n",
        "# 攻撃結果として訓練済のサロゲートモデルを得る\n",
        "thieved_classifier = attack.extract(x=X_train,\n",
        "                                    thieved_classifier=thieved_classifier)\n",
        "\n",
        "# 結果を表示する\n",
        "victim_preds = np.argmax(victim_classifier.predict(x=X_train[:100]), \n",
        "                         axis=1)\n",
        "thieved_preds = np.argmax(thieved_classifier.predict(x=X_train[:100]),\n",
        "                          axis=1)\n",
        "acc = np.sum(victim_preds == thieved_preds) / len(victim_preds)\n",
        "print('Accuracy of the surrogate model: {}%'.format(acc * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bMHA42N27Rt"
      },
      "source": [
        "### FGSM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE_uLmzR2n8q"
      },
      "source": [
        "# 改変前のX_testに対するスコアを表示する\n",
        "preds = victim_classifier.predict(X_test)\n",
        "acc = np.sum(np.argmax(preds, axis=1)\n",
        "             == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print('\\nAccuracy on benign test examples: {}%'.format(acc * 100))\n",
        "\n",
        "# 攻撃手法をインポートする\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "\n",
        "attack = FastGradientMethod(estimator=victim_classifier, eps=.1)\n",
        "\n",
        "# 攻撃の結果としてAdversarial Exampleを得る\n",
        "X_test_adv = attack.generate(x=X_test)\n",
        "\n",
        "# 改変後のX_testに対するスコアを表示する\n",
        "preds = victim_classifier.predict(X_test_adv)\n",
        "acc = np.sum(np.argmax(preds, axis=1)\n",
        "             == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print('\\nAccuracy on adversarial test examples: {}%'.format(acc * 100))\n",
        "\n",
        "# 生成したAdversarial Exampleをプロットする\n",
        "from matplotlib import pyplot as plt\n",
        "plt.matshow(X_test_adv[0, :].reshape((28, 28)))\n",
        "plt.clim(0, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcpEo-ZC3Ko1"
      },
      "source": [
        "### Carlini & Wagner Attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsFqnneM2pTs"
      },
      "source": [
        "# 攻撃手法をインポートする\n",
        "from art.attacks.evasion.carlini import CarliniL2Method\n",
        "\n",
        "# ターゲット型攻撃だが、ランダムなターゲットを指定することもできる\n",
        "from art.utils import random_targets\n",
        "\n",
        "# ここではL2ノルム最小化を試みる\n",
        "attack = CarliniL2Method(classifier=victim_classifier,\n",
        "                         targeted=True,\n",
        "                         max_iter=10)\n",
        "params = {'y': random_targets(y_test, victim_classifier.nb_classes)}\n",
        "\n",
        "# 攻撃の結果としてAdversarial Exampleを得る\n",
        "X_test_adv = attack.generate(x=X_test, **params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MLB76-G3Sp3"
      },
      "source": [
        "### ZOO Attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH9KJCmp3PjI"
      },
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# ラッパーおよびユーティリティをインポートする\n",
        "from art.estimators.classification import LightGBMClassifier\n",
        "from art.utils import load_mnist\n",
        "\n",
        "# MNISTデータセットをロードする\n",
        "(X_train, y_train), (X_test, y_test), \\\n",
        "    min_pixel_value, max_pixel_value = load_mnist()\n",
        "\n",
        "# 今回は5枚の画像にのみ摂動を加える\n",
        "X_test = X_test[0:5]\n",
        "y_test = y_test[0:5]\n",
        "\n",
        "nb_samples_train = X_train.shape[0]\n",
        "nb_samples_test = X_test.shape[0]\n",
        "X_train = X_train.reshape((nb_samples_train, 28 * 28))\n",
        "X_test = X_test.reshape((nb_samples_test, 28 * 28))\n",
        "\n",
        "# 攻撃対象のモデルを訓練する\n",
        "params = {'objective': 'multiclass',\n",
        "          'metric': 'multi_logloss',\n",
        "          'num_class': 10}\n",
        "\n",
        "lgb_train = lgb.Dataset(X_train, label=np.argmax(y_train, axis=1))\n",
        "lgb_test = lgb.Dataset(X_test, label=np.argmax(y_test, axis=1))\n",
        "model = lgb.train(params=params, train_set=lgb_train, num_boost_round=100, \n",
        "                  valid_sets=[lgb_test])\n",
        "\n",
        "victim_classifier = LightGBMClassifier(model=model,\n",
        "                                       clip_values=(min_pixel_value, max_pixel_value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYRIk8i43aiT"
      },
      "source": [
        "# 攻撃手法をインポートする\n",
        "from art.attacks.evasion import ZooAttack\n",
        "\n",
        "attack = ZooAttack(classifier=victim_classifier,\n",
        "                   confidence=0.5,\n",
        "                   targeted=False,\n",
        "                   learning_rate=1e-1,\n",
        "                   max_iter=200,\n",
        "                   binary_search_steps=100,\n",
        "                   initial_const=1e-1,\n",
        "                   nb_parallel=250,\n",
        "                   batch_size=1,\n",
        "                   variable_h=0.01)\n",
        "\n",
        "# 攻撃の結果としてAdversarial Exampleを得る\n",
        "X_test_adv = attack.generate(x=X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PojpzLX03b2U"
      },
      "source": [
        "### Adversarial Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSzKCtNq-tMk"
      },
      "source": [
        "# MNISTデータセットをロードする\n",
        "(X_train, y_train), (X_test, y_test), \\\n",
        "    min_pixel_value, max_pixel_value = load_mnist()\n",
        "\n",
        "nb_classes=10\n",
        "\n",
        "# 攻撃対象のモデルを定義する\n",
        "model = Sequential()\n",
        "model.add(Conv2D(1,kernel_size=(7, 7), activation='relu', \n",
        "                 input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(nb_classes, activation='softmax'))\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(learning_rate=0.01),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "victim_classifier = KerasClassifier(model,\n",
        "                                    clip_values=(0, 1), \n",
        "                                    use_logits=False)\n",
        "victim_classifier.fit(X_train, y_train, nb_epochs=5, batch_size=128)\n",
        "\n",
        "attack = FastGradientMethod(estimator=victim_classifier, eps=.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mhlsdSp3f00"
      },
      "source": [
        "# 防御手法をインポートする\n",
        "from art.defences.trainer.adversarial_trainer import AdversarialTrainer\n",
        "\n",
        "adv_tranier = AdversarialTrainer(victim_classifier, attack)\n",
        "adv_tranier.fit(X_train, y_train, batch_size=100, nb_epochs=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQkc6u7N3i4M"
      },
      "source": [
        "### Randomized Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx4t66HA4rXL"
      },
      "source": [
        "# TensorflowのEager Execution機能をオンオフするため、Jupyterのカーネルを再起動する\n",
        "# 「すべてのセルを実行」などで複数セルを実行している場合、手動で以降のセルから再開する必要がある\n",
        "import IPython\n",
        "IPython.Application.instance().kernel.do_shutdown(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvUj34aW3m36"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# ラッパーおよびユーティリティをインポートする\n",
        "from art.estimators.classification.keras import KerasClassifier\n",
        "from art.utils import load_mnist\n",
        "\n",
        "# MNISTデータセットをロードする\n",
        "(X_train, y_train), (X_test, y_test), \\\n",
        "    min_pixel_value, max_pixel_value = load_mnist()\n",
        "\n",
        "nb_classes=10\n",
        "\n",
        "# 攻撃対象のモデルを定義する\n",
        "model = Sequential()\n",
        "model.add(Conv2D(1,kernel_size=(7, 7), activation='relu', \n",
        "                 input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(nb_classes, activation='softmax'))\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(learning_rate=0.01),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9grmVT8a4MjR"
      },
      "source": [
        "# ARTのRandomized SmoothingはTensorFlow 2の利用を前提とする\n",
        "from art.estimators.certification.randomized_smoothing \\\n",
        "import TensorFlowV2RandomizedSmoothing\n",
        "# 訓練用のパラメータを定義する\n",
        "nb_classes=10\n",
        "nb_epochs = 40\n",
        "batch_size = 128\n",
        "input_shape = X_train.shape[1:]\n",
        "alpha = 0.001\n",
        "sample_size = 100\n",
        "\n",
        "# TensorFlowのパラメータ更新用関数を定義する\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "def train_step(model, images, labels):        \n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images, training=True)\n",
        "        loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0bmNszm4bZ9"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# 異なる分散のガウシアンノイズを定義する\n",
        "sigmas = {\n",
        "    'Smoothed Classifier, sigma=0.1': 0.1,\n",
        "    'Smoothed Classifier, sigma=0.25': 0.25,\n",
        "    'Smoothed Classifier, sigma=0.5': 0.5\n",
        "}\n",
        "classifiers = {}\n",
        "\n",
        "def get_cert_acc(radius, pred, y_test):\n",
        "\n",
        "    rad_list = np.linspace(0, 2.25, 201)\n",
        "    cert_acc = []\n",
        "    num_cert = len(np.where(radius > 0)[0])\n",
        "    \n",
        "    for r in rad_list:\n",
        "        rad_idx = np.where(radius > r)[0]\n",
        "        y_test_subset = y_test[rad_idx]\n",
        "        cert_acc.append(np.sum(pred[rad_idx] == \\\n",
        "                               np.argmax(y_test_subset, axis=1)) / num_cert)\n",
        "        \n",
        "    return cert_acc\n",
        "\n",
        "for name in sigmas:\n",
        "    sigma = sigmas[name]\n",
        "\n",
        "    # 「平滑化された」分類器を訓練する\n",
        "    classifier = \\\n",
        "    TensorFlowV2RandomizedSmoothing(model=model,\n",
        "                                    nb_classes=nb_classes,\n",
        "                                    input_shape=input_shape,\n",
        "                                    loss_object=loss_object,\n",
        "                                    train_step=train_step,\n",
        "                                    channels_first=False,\n",
        "                                    clip_values=(min_pixel_value, \n",
        "                                                 max_pixel_value),\n",
        "                                    sample_size=sample_size,\n",
        "                                    scale=sigma,\n",
        "                                    alpha=alpha)\n",
        "\n",
        "    classifier.fit(X_train, y_train, nb_epochs=nb_epochs,\n",
        "                   batch_size=batch_size)\n",
        "    \n",
        "    # Certified Accuracyを取得する\n",
        "    cert_preds, radius = classifier.certify(X_test, n=500)\n",
        "    \n",
        "    # 半径ごとにCertified Accuracyをプロットする\n",
        "    rad_list = np.linspace(0, 2.25, 201)\n",
        "    plt.plot(rad_list, get_cert_acc(radius, cert_preds, y_test),\n",
        "             label=name)\n",
        "\n",
        "    classifiers[name] = classifier\n",
        "\n",
        "plt.xlabel('radius')\n",
        "plt.ylabel('certified accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBcbSYVR4i6e"
      },
      "source": [
        "### BadNets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLCg_Hfm46Nv"
      },
      "source": [
        "# TensorflowのEager Execution機能をオンオフするため、Jupyterのカーネルを再起動する\n",
        "# 「すべてのセルを実行」などで複数セルを実行している場合、手動で以降のセルから再開する必要がある\n",
        "import IPython\n",
        "IPython.Application.instance().kernel.do_shutdown(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wyb9Eg64kXa"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# ラッパーおよびユーティリティをインポートする\n",
        "from art.estimators.classification.keras import KerasClassifier\n",
        "from art.utils import load_mnist, preprocess\n",
        "\n",
        "# MNISTデータセットをロードする\n",
        "# 今回は正規化される前のデータを加工するため、raw=Trueとする\n",
        "(X_train_raw, y_train_raw), (X_test_raw, y_test_raw), \\\n",
        "    min_pixel_value, max_pixel_value = load_mnist(raw=True)\n",
        "nb_classes=10\n",
        "\n",
        "# 攻撃手法をインポートする\n",
        "from art.attacks.poisoning import PoisoningAttackBackdoor\n",
        "from art.attacks.poisoning.perturbations import add_pattern_bd\n",
        "\n",
        "# 画像の右下にトリガーを埋め込む\n",
        "max_val = np.max(X_train_raw)\n",
        "def add_modification(x):\n",
        "    return add_pattern_bd(x, pixel_value=max_val)\n",
        "\n",
        "# データセットを汚染する\n",
        "def poison_dataset(X_clean, y_clean, percent_poison, poison_func):\n",
        "    X_poison = np.copy(X_clean)\n",
        "    y_poison = np.copy(y_clean)\n",
        "    is_poison = np.zeros(np.shape(y_poison))\n",
        "    \n",
        "    sources=np.arange(nb_classes)\n",
        "    targets=(np.arange(nb_classes) + 1) % nb_classes\n",
        "\n",
        "    # 訓練データから汚染対象のデータを選択し、ノイズを加える\n",
        "    for i, (src, tgt) in enumerate(zip(sources, targets)):\n",
        "        n_points_in_tgt = np.size(np.where(y_clean == tgt))\n",
        "        num_poison = round((percent_poison * n_points_in_tgt)\n",
        "                           / (1 - percent_poison))\n",
        "\n",
        "        src_imgs = X_clean[y_clean == src]\n",
        "\n",
        "        n_points_in_src = np.shape(src_imgs)[0]\n",
        "        indices_to_be_poisoned = np.random.choice(n_points_in_src, \n",
        "                                                  num_poison)\n",
        "\n",
        "        imgs_to_be_poisoned = np.copy(src_imgs[indices_to_be_poisoned])\n",
        "\n",
        "        # 攻撃を初期化する\n",
        "        attack = PoisoningAttackBackdoor(add_modification)\n",
        "        \n",
        "        # 攻撃を実行する\n",
        "        imgs_to_be_poisoned, poison_labels = \\\n",
        "        attack.poison(imgs_to_be_poisoned, y=np.ones(num_poison) * tgt)\n",
        "        \n",
        "        X_poison = np.append(X_poison, imgs_to_be_poisoned, axis=0)\n",
        "        y_poison = np.append(y_poison, poison_labels, axis=0)\n",
        "        is_poison = np.append(is_poison, np.ones(num_poison))\n",
        "\n",
        "    is_poison = is_poison != 0\n",
        "\n",
        "    return is_poison, X_poison, y_poison\n",
        "    \n",
        "# 訓練データの33%を汚染する\n",
        "percent_poison = .33\n",
        "\n",
        "(is_poison_train, X_poisoned_train_raw, y_poisoned_train_raw) = \\\n",
        "poison_dataset(X_train_raw, y_train_raw, percent_poison, add_modification)\n",
        "X_train, y_train = preprocess(X_poisoned_train_raw, y_poisoned_train_raw)\n",
        "X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "(is_poison_test, X_poisoned_test_raw, y_poisoned_test_raw) = \\\n",
        "poison_dataset(X_test_raw, y_test_raw, percent_poison, add_modification)\n",
        "X_test, y_test = preprocess(X_poisoned_test_raw, y_poisoned_test_raw)\n",
        "X_test = np.expand_dims(X_test, axis=3)\n",
        "\n",
        "# 訓練データをシャッフルする\n",
        "n_train = len(y_train)\n",
        "shuffled_indices = np.arange(n_train)\n",
        "np.random.shuffle(shuffled_indices)\n",
        "X_train = X_train[shuffled_indices]\n",
        "y_train = y_train[shuffled_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3p5WBkn47J-"
      },
      "source": [
        "# 攻撃対象のモデルを定義する\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), \n",
        "                 activation='relu', \n",
        "                 input_shape=X_train.shape[1:]))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(nb_classes, activation='softmax'))\n",
        "model.compile(loss=categorical_crossentropy, \n",
        "              optimizer=Adam(learning_rate=0.01),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "victim_classifier = KerasClassifier(model,\n",
        "                                    clip_values=(0, 1), \n",
        "                                    use_logits=False)\n",
        "# 汚染されたデータでモデルを訓練する\n",
        "victim_classifier.fit(X_train, y_train, nb_epochs=30, batch_size=128)\n",
        "\n",
        "# 汚染されていないデータに対するスコアを表示する\n",
        "clean_X_test = X_test[is_poison_test == 0]\n",
        "clean_y_test = y_test[is_poison_test == 0]\n",
        "\n",
        "clean_preds = victim_classifier.predict(clean_X_test)\n",
        "acc = np.sum(np.argmax(clean_preds, axis=1)\n",
        "    == np.argmax(clean_y_test, axis=1)) / len(clean_y_test)\n",
        "print('\\nAccuracy on clean test examples: {}%'.format(acc * 100))\n",
        "\n",
        "# 汚染されたデータに対するスコアを表示する\n",
        "poison_X_test = X_test[is_poison_test]\n",
        "poison_y_test = y_test[is_poison_test]\n",
        "\n",
        "poison_preds = victim_classifier.predict(poison_X_test)\n",
        "acc = np.sum(np.argmax(poison_preds, axis=1)\n",
        "    == np.argmax(poison_y_test, axis=1)) / len(poison_y_test)\n",
        "print('\\nAccuracy on poisoned test examples: {}%'.format(acc * 100))\n",
        "\n",
        "# データ全体に対するスコアを表示する\n",
        "clean_correct = np.sum(np.argmax(clean_preds, axis=1) \n",
        "                       == np.argmax(clean_y_test, axis=1))\n",
        "poison_correct = np.sum(np.argmax(poison_preds, axis=1)\n",
        "                        == np.argmax(poison_y_test, axis=1))\n",
        "total_correct = clean_correct + poison_correct\n",
        "total = len(clean_y_test) + len(poison_y_test)\n",
        "total_acc = total_correct / total\n",
        "\n",
        "print(\"\\nOverall accuracy on test examples: {}%\".format(total_acc * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71NRWaQa4-3R"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "c = 1 # プロット対象のクラス\n",
        "i = 0 # 画像の添字\n",
        "\n",
        "c_idx = np.where(np.argmax(poison_y_test,1) == c)[0][i]\n",
        "\n",
        "plt.imshow(poison_X_test[c_idx].squeeze())\n",
        "plt.show()\n",
        "\n",
        "print('Prediction: {}'.format(np.argmax(poison_preds[c_idx])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZFDoy7J5DkN"
      },
      "source": [
        "### Activation Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc4bLqS85Bsa"
      },
      "source": [
        "# 防御手法をインポートする\n",
        "from art.defences.detector.poison import ActivationDefence\n",
        "\n",
        "defence = ActivationDefence(victim_classifier, X_train, y_train)\n",
        "\n",
        "# PCAで次元削減を施したのち、2つのクラスタに分割する\n",
        "report, is_clean_lst = defence.detect_poison(nb_clusters=2,\n",
        "                                             nb_dims=10,\n",
        "                                             reduce='PCA')\n",
        "\n",
        "[clusters_by_class, _] = defence.cluster_activations()\n",
        "\n",
        "# 指定したクラスのデータのクラスタリング結果をプロットする関数を定義する\n",
        "def plot_class_clusters(sprites_by_class, n_class, n_clusters):\n",
        "    for q in range(n_clusters):\n",
        "        plt.figure(1, figsize=(25,25))\n",
        "        plt.tight_layout()\n",
        "        plt.subplot(1, n_clusters, q+1)\n",
        "        plt.title('Class '+ str(n_class)+ ', Cluster '+ str(q),\n",
        "                  fontsize=40)\n",
        "        sprite = sprites_by_class[n_class][q]\n",
        "        plt.imshow(sprite, interpolation='none')\n",
        "        \n",
        "# 訓練データをクラスごとに分割し、\n",
        "sprites_by_class = defence.visualize_clusters(X_train, save=False)\n",
        "# ここではクラス1に対するクラスタリング結果をプロットする\n",
        "plot_class_clusters(sprites_by_class, 1, 2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}