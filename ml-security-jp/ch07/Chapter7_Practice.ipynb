{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter7-Practice",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcGpeVDBTyUN"
      },
      "source": [
        "![表紙](https://www.oreilly.co.jp/books/images/picture978-4-87311-907-6.gif)\n",
        "\n",
        "このノートブックはオライリー・ジャパンより発行の書籍[『セキュリティエンジニアのための機械学習』](https://www.oreilly.co.jp/books/9784873119076/)のサンプルコードです。コードの解説等は書籍をご参照ください。なお、このコードを動作させた結果について、著者およびオライリー・ジャパンは一切の責任を負いません。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMCi4Uuvf1vk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad089acd-7cfa-403b-e480-c875b03d28c8"
      },
      "source": [
        "!git clone https://github.com/Morzeux/HttpParamsDataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HttpParamsDataset'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Total 17 (delta 0), reused 0 (delta 0), pack-reused 17\u001b[K\n",
            "Unpacking objects: 100% (17/17), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHsiFovVVtze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6199b619-1d6c-4f6e-e73d-c4b5a515cb2e"
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.9.1-py3-none-any.whl (302 kB)\n",
            "\u001b[K     |████████████████████████████████| 302 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.9.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.0)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.3-py3-none-any.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 56.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.4.1-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.25)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.8.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.2.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 74.5 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.4.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.2.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.4.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.2.0-py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 72.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=bcfedfae77d4a5e6b902cbb2a423a4c4b9bf5caf115f41aa67b6ea1e8278b458\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, colorama, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.5 alembic-1.7.3 autopage-0.4.0 cliff-3.9.0 cmaes-0.8.2 cmd2-2.2.0 colorama-0.4.4 colorlog-6.4.1 optuna-2.9.1 pbr-5.6.0 pyperclip-1.8.2 stevedore-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pIc_E9jg2ft"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('./HttpParamsDataset/payload_train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB7rIG1MEIEn"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# HTTPクエリストリングのエントロピーの計算\n",
        "def H_entropy(x):\n",
        "    prob = [ float(x.count(c)) / len(x) for c in dict.fromkeys(list(x)) ] \n",
        "    H = - sum([ p * np.log2(p) for p in prob ]) \n",
        "    return H"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV8m8Pyhy4Gh"
      },
      "source": [
        "# 通常であるとラベリングされた行列のみを抽出\n",
        "df_norm = df[df.attack_type == 'norm']\n",
        "\n",
        "# 算出されたエントロピーを格納するリストを用意\n",
        "norm_entropies = []\n",
        "\n",
        "# payload列からHTTPクエリストリングを取り出して処理させる\n",
        "for i in df_norm['payload']:\n",
        "    \n",
        "    # エントロピーの計算と代入\n",
        "    norm_entropies.append(H_entropy(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhDeqtfizQDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31eb9e2a-1b83-40f6-f477-a8d540269ce3"
      },
      "source": [
        "sum(norm_entropies) / len(norm_entropies)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.7658075808985836"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os-r5I-mx0cW"
      },
      "source": [
        "# SQLインジェクションであるとラベリングされた行列のみを抽出\n",
        "df_sqli = df[df.attack_type == 'sqli']\n",
        "\n",
        "# 算出されたエントロピーを格納するリストを用意\n",
        "sqli_entropies = []\n",
        "\n",
        "# payload列からHTTPクエリストリングを取り出して処理させる\n",
        "for i in df_sqli['payload']:\n",
        "    \n",
        "    # エントロピーの計算と代入\n",
        "    sqli_entropies.append(H_entropy(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4_nweN2yl3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d49f28fd-8afb-4923-b1ba-f81d557129e9"
      },
      "source": [
        "sum(sqli_entropies) / len(sqli_entropies)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.289379819336267"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxSF5xxJzeTJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "09f5fb07-c214-4fee-fc67-fddeefe31a32"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# グラフのタイトルとラベルの設定\n",
        "ax.set_title('Entropies of normal HTTP query string')\n",
        "ax.set_xlabel('Entropy')\n",
        "ax.set_ylabel('Numbers')\n",
        "\n",
        "# 度数分布グラフの描画\n",
        "plt.hist(norm_entropies, bins=30, range=(0,6), color='green')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0BVRBvKH5MX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "bab06a27-a703-4e63-fd85-285fe597c374"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# グラフのタイトルとラベルの設定\n",
        "ax.set_title('Entropies of SQLi HTTP query string')\n",
        "ax.set_xlabel('Entropy')\n",
        "ax.set_ylabel('Numbers')\n",
        "\n",
        "# 度数分布グラフの描画\n",
        "plt.hist(sqli_entropies, bins=30, range=(0,6), color='red')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnXMZNCXmF03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "d1a41cb7-0c1d-423c-bd3e-ad1adfc6e05e"
      },
      "source": [
        "df_sqli = df[df.attack_type == 'sqli']\n",
        "df_sqli"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>payload</th>\n",
              "      <th>length</th>\n",
              "      <th>attack_type</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>1' where 6406=6406;select count(*) from rdb$fi...</td>\n",
              "      <td>115</td>\n",
              "      <td>sqli</td>\n",
              "      <td>anom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>1) and 8514=(select count(*) from domain.domai...</td>\n",
              "      <td>111</td>\n",
              "      <td>sqli</td>\n",
              "      <td>anom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>1) where 7956=7956 or sleep(5)#</td>\n",
              "      <td>31</td>\n",
              "      <td>sqli</td>\n",
              "      <td>anom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>-7387'))) order by 1--</td>\n",
              "      <td>22</td>\n",
              "      <td>sqli</td>\n",
              "      <td>anom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>1))) union all select null,null,null#</td>\n",
              "      <td>37</td>\n",
              "      <td>sqli</td>\n",
              "      <td>anom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20360</th>\n",
              "      <td>1%\")) and elt(4249=4249,7259) and ((\"%\"=\"</td>\n",
              "      <td>41</td>\n",
              "      <td>sqli</td>\n",
              "      <td>anom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20361</th>\n",
              "      <td>-7773' or 5903=('qqpjq'||(select case 5903 whe...</td>\n",
              "      <td>99</td>\n",
              "      <td>sqli</td>\n",
              "      <td>anom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20362</th>\n",
              "      <td>1\" order by 1--</td>\n",
              "      <td>15</td>\n",
              "      <td>sqli</td>\n",
              "      <td>anom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20363</th>\n",
              "      <td>1' procedure analyse(extractvalue(5840,concat(...</td>\n",
              "      <td>149</td>\n",
              "      <td>sqli</td>\n",
              "      <td>anom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20364</th>\n",
              "      <td>-7511)) as xqzf where 9939=9939 union all sele...</td>\n",
              "      <td>85</td>\n",
              "      <td>sqli</td>\n",
              "      <td>anom</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7235 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 payload  ...  label\n",
              "291    1' where 6406=6406;select count(*) from rdb$fi...  ...   anom\n",
              "292    1) and 8514=(select count(*) from domain.domai...  ...   anom\n",
              "293                      1) where 7956=7956 or sleep(5)#  ...   anom\n",
              "294                               -7387'))) order by 1--  ...   anom\n",
              "295                1))) union all select null,null,null#  ...   anom\n",
              "...                                                  ...  ...    ...\n",
              "20360          1%\")) and elt(4249=4249,7259) and ((\"%\"=\"  ...   anom\n",
              "20361  -7773' or 5903=('qqpjq'||(select case 5903 whe...  ...   anom\n",
              "20362                                    1\" order by 1--  ...   anom\n",
              "20363  1' procedure analyse(extractvalue(5840,concat(...  ...   anom\n",
              "20364  -7511)) as xqzf where 9939=9939 union all sele...  ...   anom\n",
              "\n",
              "[7235 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtKqoYN0dX2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "283bbb4c-18ae-4544-b5b3-2c8694977392"
      },
      "source": [
        "print('{:.2%}'.format(df_sqli['payload'].str.contains('\\)').sum() / len(df_sqli['payload'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DJ7I-oekCSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577f6509-0bf2-4be4-c38a-53cfa20e9189"
      },
      "source": [
        "df_norm = df[df.attack_type == 'norm']\n",
        "print('{:.2%}'.format(df_norm['payload'].str.contains('\\)').sum() / len(df_norm['payload'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAR_B1dXjNRv"
      },
      "source": [
        "def func_preprocessing(df):\n",
        "    train_rows = ((df.attack_type == 'norm') | (df.attack_type == 'sqli'))\n",
        "    df = df[train_rows]\n",
        "\n",
        "    # エントロピーと閉じ括弧の有無を入れる配列\n",
        "    entropies = []\n",
        "    closing_parenthesis = []\n",
        "    \n",
        "    # payload列からHTTPクエリストリングを取り出して処理させる\n",
        "    for i in df['payload']:\n",
        "        # エントロピーの計算と代入\n",
        "        entropies.append(H_entropy(i))\n",
        "        \n",
        "        # 閉じ括弧を検出して、存在した場合は列closing_parenthesisに1を設定、ない場合は0を設定\n",
        "        if i.count(')'):\n",
        "            closing_parenthesis.append(1)\n",
        "        else:\n",
        "            closing_parenthesis.append(0)\n",
        "    \n",
        "    # データセットに新たに列を追加\n",
        "    df = df.assign(entropy=entropies)\n",
        "    df = df.assign(closing_parenthesis=closing_parenthesis)\n",
        "    \n",
        "    # データセットのlabel列のnormを0に、anormを1に変更\n",
        "    rep = df.label.replace({\"norm\":0,\"anom\":1})\n",
        "    df = df.assign(label=rep)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWhG2qeeodOa"
      },
      "source": [
        "df = func_preprocessing(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO5tBiEFaM7Y"
      },
      "source": [
        "# 交差検証を行うため、テスト用に分割されているデータも読み込んで単一の行列にする\n",
        "# テストデータのロード\n",
        "test_data = pd.read_csv('./HttpParamsDataset/payload_test.csv')\n",
        "test_data = func_preprocessing(test_data)\n",
        "\n",
        "# 特徴量に使用する列のみを抽出\n",
        "df_x = df[['length','entropy','closing_parenthesis']]\n",
        "test_x = test_data[['length','entropy','closing_parenthesis']]\n",
        "\n",
        "# ラベルのみを抽出\n",
        "df_y = df[['label']]\n",
        "test_y = test_data[['label']]\n",
        "\n",
        "# 特徴量とラベルとして、それぞれひとつにまとめる\n",
        "X_all = pd.concat([df_x, test_x])\n",
        "y_all = pd.concat([df_y, test_y])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BzD5Yl5emtK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "0720c97b-eea2-46e3-cb1a-1afbc895c882"
      },
      "source": [
        "X_all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>entropy</th>\n",
              "      <th>closing_parenthesis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14</td>\n",
              "      <td>3.093069</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12</td>\n",
              "      <td>3.022055</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16</td>\n",
              "      <td>2.827820</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>2.321928</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>3.378783</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10176</th>\n",
              "      <td>113</td>\n",
              "      <td>4.422041</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10177</th>\n",
              "      <td>113</td>\n",
              "      <td>4.514233</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10178</th>\n",
              "      <td>136</td>\n",
              "      <td>4.630369</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10179</th>\n",
              "      <td>111</td>\n",
              "      <td>4.539371</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10180</th>\n",
              "      <td>53</td>\n",
              "      <td>4.130354</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30156 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       length   entropy  closing_parenthesis\n",
              "0          14  3.093069                    0\n",
              "1          12  3.022055                    0\n",
              "2          16  2.827820                    0\n",
              "3           5  2.321928                    0\n",
              "4          14  3.378783                    0\n",
              "...       ...       ...                  ...\n",
              "10176     113  4.422041                    1\n",
              "10177     113  4.514233                    1\n",
              "10178     136  4.630369                    1\n",
              "10179     111  4.539371                    1\n",
              "10180      53  4.130354                    1\n",
              "\n",
              "[30156 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osOCCB9uGkFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9a823b6-3463-4f55-9dbc-ef5686f8759a"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "\n",
        "# データセットを訓練用とテスト用に分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, shuffle=True, random_state=101)\n",
        "\n",
        "class Objective_DTC:\n",
        "    def __init__(self, X, y):\n",
        "        # 変数 X,y の初期化\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __call__(self, trial):\n",
        "        # チューニング対象のハイパーパラメータの設定\n",
        "        params ={\n",
        "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 64)\n",
        "        }\n",
        "        model = DecisionTreeClassifier(**params)\n",
        "        # 交差検証の設定\n",
        "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "        scores = cross_validate(model,\n",
        "                                X=self.X, y=self.y,\n",
        "                                cv=kf,\n",
        "                                scoring='neg_log_loss',\n",
        "                                n_jobs=-1)\n",
        "        # 交差検証結果の平均を戻り値に設定\n",
        "        return scores['test_score'].mean()\n",
        "\n",
        "objective = Objective_DTC(X_train, y_train)\n",
        "study = optuna.create_study()\n",
        "study.optimize(objective, timeout=60)\n",
        "print('params:', study.best_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:45:05,169]\u001b[0m A new study created in memory with name: no-name-f93d6656-c1ca-4bca-95e6-c3a5838d6f00\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:06,615]\u001b[0m Trial 0 finished with value: -0.47731562369704256 and parameters: {'criterion': 'entropy', 'max_depth': 23}. Best is trial 0 with value: -0.47731562369704256.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:06,743]\u001b[0m Trial 1 finished with value: -0.3664686625141009 and parameters: {'criterion': 'gini', 'max_depth': 13}. Best is trial 0 with value: -0.47731562369704256.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:06,891]\u001b[0m Trial 2 finished with value: -0.5050906971200649 and parameters: {'criterion': 'entropy', 'max_depth': 28}. Best is trial 2 with value: -0.5050906971200649.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:07,019]\u001b[0m Trial 3 finished with value: -0.5022637429302982 and parameters: {'criterion': 'gini', 'max_depth': 56}. Best is trial 2 with value: -0.5050906971200649.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:07,166]\u001b[0m Trial 4 finished with value: -0.444643489618387 and parameters: {'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: -0.5050906971200649.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:07,288]\u001b[0m Trial 5 finished with value: -0.2225699796506401 and parameters: {'criterion': 'gini', 'max_depth': 10}. Best is trial 2 with value: -0.5050906971200649.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:07,434]\u001b[0m Trial 6 finished with value: -0.5020499771220199 and parameters: {'criterion': 'entropy', 'max_depth': 58}. Best is trial 2 with value: -0.5050906971200649.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:07,567]\u001b[0m Trial 7 finished with value: -0.4980121429660628 and parameters: {'criterion': 'gini', 'max_depth': 24}. Best is trial 2 with value: -0.5050906971200649.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:07,719]\u001b[0m Trial 8 finished with value: -0.5062569983965732 and parameters: {'criterion': 'entropy', 'max_depth': 51}. Best is trial 8 with value: -0.5062569983965732.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:07,851]\u001b[0m Trial 9 finished with value: -0.43760823198199506 and parameters: {'criterion': 'gini', 'max_depth': 15}. Best is trial 8 with value: -0.5062569983965732.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:07,986]\u001b[0m Trial 10 finished with value: -0.5034511431249171 and parameters: {'criterion': 'entropy', 'max_depth': 42}. Best is trial 8 with value: -0.5062569983965732.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:08,128]\u001b[0m Trial 11 finished with value: -0.5062832554141781 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 11 with value: -0.5062832554141781.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:08,274]\u001b[0m Trial 12 finished with value: -0.502010196457421 and parameters: {'criterion': 'entropy', 'max_depth': 41}. Best is trial 11 with value: -0.5062832554141781.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:08,411]\u001b[0m Trial 13 finished with value: -0.5020064552230884 and parameters: {'criterion': 'entropy', 'max_depth': 45}. Best is trial 11 with value: -0.5062832554141781.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:08,550]\u001b[0m Trial 14 finished with value: -0.5033943072183389 and parameters: {'criterion': 'entropy', 'max_depth': 50}. Best is trial 11 with value: -0.5062832554141781.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:08,686]\u001b[0m Trial 15 finished with value: -0.5020074514945557 and parameters: {'criterion': 'entropy', 'max_depth': 64}. Best is trial 11 with value: -0.5062832554141781.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:08,784]\u001b[0m Trial 16 finished with value: -0.13498165094499648 and parameters: {'criterion': 'entropy', 'max_depth': 1}. Best is trial 11 with value: -0.5062832554141781.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:08,927]\u001b[0m Trial 17 finished with value: -0.5034044653061442 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 11 with value: -0.5062832554141781.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:09,071]\u001b[0m Trial 18 finished with value: -0.5062542327378858 and parameters: {'criterion': 'entropy', 'max_depth': 33}. Best is trial 11 with value: -0.5062832554141781.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:09,212]\u001b[0m Trial 19 finished with value: -0.5105451117618671 and parameters: {'criterion': 'entropy', 'max_depth': 50}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:09,351]\u001b[0m Trial 20 finished with value: -0.5048786965018479 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:09,488]\u001b[0m Trial 21 finished with value: -0.5005518857355059 and parameters: {'criterion': 'entropy', 'max_depth': 50}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:09,626]\u001b[0m Trial 22 finished with value: -0.5091689214443451 and parameters: {'criterion': 'entropy', 'max_depth': 49}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:09,765]\u001b[0m Trial 23 finished with value: -0.49922900746749804 and parameters: {'criterion': 'entropy', 'max_depth': 46}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:09,906]\u001b[0m Trial 24 finished with value: -0.4991154408547331 and parameters: {'criterion': 'entropy', 'max_depth': 57}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:10,046]\u001b[0m Trial 25 finished with value: -0.5034727004660889 and parameters: {'criterion': 'entropy', 'max_depth': 41}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:10,180]\u001b[0m Trial 26 finished with value: -0.5007640824712077 and parameters: {'criterion': 'gini', 'max_depth': 64}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:10,323]\u001b[0m Trial 27 finished with value: -0.504940853201033 and parameters: {'criterion': 'entropy', 'max_depth': 53}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:10,461]\u001b[0m Trial 28 finished with value: -0.5034122733390544 and parameters: {'criterion': 'entropy', 'max_depth': 46}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:10,609]\u001b[0m Trial 29 finished with value: -0.5006304262310552 and parameters: {'criterion': 'entropy', 'max_depth': 29}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:10,746]\u001b[0m Trial 30 finished with value: -0.5019832540313345 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:10,887]\u001b[0m Trial 31 finished with value: -0.5020488757051451 and parameters: {'criterion': 'entropy', 'max_depth': 51}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:11,022]\u001b[0m Trial 32 finished with value: -0.5048469357124497 and parameters: {'criterion': 'entropy', 'max_depth': 54}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:11,160]\u001b[0m Trial 33 finished with value: -0.5048907152967952 and parameters: {'criterion': 'entropy', 'max_depth': 59}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:11,318]\u001b[0m Trial 34 finished with value: -0.505043978250216 and parameters: {'criterion': 'gini', 'max_depth': 47}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:11,465]\u001b[0m Trial 35 finished with value: -0.5091642820998348 and parameters: {'criterion': 'entropy', 'max_depth': 30}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:11,612]\u001b[0m Trial 36 finished with value: -0.4896484021947143 and parameters: {'criterion': 'entropy', 'max_depth': 26}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:11,746]\u001b[0m Trial 37 finished with value: -0.5080241256944673 and parameters: {'criterion': 'gini', 'max_depth': 30}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:11,882]\u001b[0m Trial 38 finished with value: -0.5009892199146659 and parameters: {'criterion': 'gini', 'max_depth': 21}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:12,014]\u001b[0m Trial 39 finished with value: -0.5079483823540408 and parameters: {'criterion': 'gini', 'max_depth': 28}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:12,146]\u001b[0m Trial 40 finished with value: -0.5079077593631359 and parameters: {'criterion': 'gini', 'max_depth': 31}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:12,286]\u001b[0m Trial 41 finished with value: -0.49523661230094546 and parameters: {'criterion': 'gini', 'max_depth': 21}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:12,419]\u001b[0m Trial 42 finished with value: -0.503673005342642 and parameters: {'criterion': 'gini', 'max_depth': 28}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:12,558]\u001b[0m Trial 43 finished with value: -0.4979954083660204 and parameters: {'criterion': 'gini', 'max_depth': 32}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:12,701]\u001b[0m Trial 44 finished with value: -0.49511091680185837 and parameters: {'criterion': 'gini', 'max_depth': 23}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:12,893]\u001b[0m Trial 45 finished with value: -0.31825922128730416 and parameters: {'criterion': 'gini', 'max_depth': 12}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:13,030]\u001b[0m Trial 46 finished with value: -0.4869891770121013 and parameters: {'criterion': 'gini', 'max_depth': 19}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:13,160]\u001b[0m Trial 47 finished with value: -0.5022135741281869 and parameters: {'criterion': 'gini', 'max_depth': 26}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:13,311]\u001b[0m Trial 48 finished with value: -0.4738258248574743 and parameters: {'criterion': 'gini', 'max_depth': 16}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:13,439]\u001b[0m Trial 49 finished with value: -0.5051302512756229 and parameters: {'criterion': 'gini', 'max_depth': 30}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:13,571]\u001b[0m Trial 50 finished with value: -0.5050969615611881 and parameters: {'criterion': 'gini', 'max_depth': 43}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:13,702]\u001b[0m Trial 51 finished with value: -0.503648126205444 and parameters: {'criterion': 'gini', 'max_depth': 32}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:13,832]\u001b[0m Trial 52 finished with value: -0.5036194006720416 and parameters: {'criterion': 'gini', 'max_depth': 35}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:13,960]\u001b[0m Trial 53 finished with value: -0.5008517173131896 and parameters: {'criterion': 'gini', 'max_depth': 25}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:14,091]\u001b[0m Trial 54 finished with value: -0.5022668939253855 and parameters: {'criterion': 'gini', 'max_depth': 36}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:14,220]\u001b[0m Trial 55 finished with value: -0.5007699631695313 and parameters: {'criterion': 'gini', 'max_depth': 60}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:14,371]\u001b[0m Trial 56 finished with value: -0.5020707881679737 and parameters: {'criterion': 'entropy', 'max_depth': 30}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:14,498]\u001b[0m Trial 57 finished with value: -0.506499619242114 and parameters: {'criterion': 'gini', 'max_depth': 39}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:14,635]\u001b[0m Trial 58 finished with value: -0.5005517531597662 and parameters: {'criterion': 'entropy', 'max_depth': 34}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:14,762]\u001b[0m Trial 59 finished with value: -0.09966885127556538 and parameters: {'criterion': 'entropy', 'max_depth': 7}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:14,901]\u001b[0m Trial 60 finished with value: -0.49946606466657306 and parameters: {'criterion': 'gini', 'max_depth': 28}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:15,033]\u001b[0m Trial 61 finished with value: -0.5050530762314966 and parameters: {'criterion': 'gini', 'max_depth': 41}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:15,162]\u001b[0m Trial 62 finished with value: -0.5036818121369799 and parameters: {'criterion': 'gini', 'max_depth': 48}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:15,301]\u001b[0m Trial 63 finished with value: -0.49792800998812065 and parameters: {'criterion': 'gini', 'max_depth': 39}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:15,426]\u001b[0m Trial 64 finished with value: -0.5008472316895152 and parameters: {'criterion': 'gini', 'max_depth': 43}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:15,571]\u001b[0m Trial 65 finished with value: -0.5020850651329198 and parameters: {'criterion': 'entropy', 'max_depth': 32}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:15,711]\u001b[0m Trial 66 finished with value: -0.50341352031035 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:15,841]\u001b[0m Trial 67 finished with value: -0.5036478081881073 and parameters: {'criterion': 'gini', 'max_depth': 44}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:15,980]\u001b[0m Trial 68 finished with value: -0.5048216237843024 and parameters: {'criterion': 'entropy', 'max_depth': 55}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:16,115]\u001b[0m Trial 69 finished with value: -0.49779896572996163 and parameters: {'criterion': 'entropy', 'max_depth': 49}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:16,244]\u001b[0m Trial 70 finished with value: -0.5050724851980866 and parameters: {'criterion': 'gini', 'max_depth': 52}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:16,388]\u001b[0m Trial 71 finished with value: -0.5049237833894118 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:16,528]\u001b[0m Trial 72 finished with value: -0.49916400655226767 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:16,664]\u001b[0m Trial 73 finished with value: -0.5091932500425579 and parameters: {'criterion': 'entropy', 'max_depth': 30}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:16,814]\u001b[0m Trial 74 finished with value: -0.49661293152323777 and parameters: {'criterion': 'entropy', 'max_depth': 27}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:16,963]\u001b[0m Trial 75 finished with value: -0.48442769602369246 and parameters: {'criterion': 'entropy', 'max_depth': 24}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:17,098]\u001b[0m Trial 76 finished with value: -0.5020649535731373 and parameters: {'criterion': 'entropy', 'max_depth': 33}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:17,233]\u001b[0m Trial 77 finished with value: -0.4977822336018608 and parameters: {'criterion': 'entropy', 'max_depth': 31}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:17,367]\u001b[0m Trial 78 finished with value: -0.5007700235014539 and parameters: {'criterion': 'gini', 'max_depth': 29}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:17,502]\u001b[0m Trial 79 finished with value: -0.48158314318424056 and parameters: {'criterion': 'entropy', 'max_depth': 22}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:17,627]\u001b[0m Trial 80 finished with value: -0.5050630175866444 and parameters: {'criterion': 'gini', 'max_depth': 27}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:17,765]\u001b[0m Trial 81 finished with value: -0.5062529526226552 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:17,904]\u001b[0m Trial 82 finished with value: -0.503509292066912 and parameters: {'criterion': 'entropy', 'max_depth': 30}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:18,043]\u001b[0m Trial 83 finished with value: -0.5049449578661254 and parameters: {'criterion': 'entropy', 'max_depth': 34}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:18,183]\u001b[0m Trial 84 finished with value: -0.5048253590626877 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:18,324]\u001b[0m Trial 85 finished with value: -0.4991668384988248 and parameters: {'criterion': 'entropy', 'max_depth': 45}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:18,462]\u001b[0m Trial 86 finished with value: -0.5064491324226658 and parameters: {'criterion': 'gini', 'max_depth': 25}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:18,590]\u001b[0m Trial 87 finished with value: -0.4798414997952717 and parameters: {'criterion': 'gini', 'max_depth': 19}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:18,729]\u001b[0m Trial 88 finished with value: -0.49798553329874257 and parameters: {'criterion': 'gini', 'max_depth': 26}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:18,855]\u001b[0m Trial 89 finished with value: -0.4966165217763108 and parameters: {'criterion': 'gini', 'max_depth': 24}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:18,995]\u001b[0m Trial 90 finished with value: -0.5079722044570335 and parameters: {'criterion': 'gini', 'max_depth': 31}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:19,120]\u001b[0m Trial 91 finished with value: -0.4993579710539513 and parameters: {'criterion': 'gini', 'max_depth': 31}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:19,265]\u001b[0m Trial 92 finished with value: -0.4966096178608767 and parameters: {'criterion': 'gini', 'max_depth': 29}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:19,402]\u001b[0m Trial 93 finished with value: -0.4994612631952086 and parameters: {'criterion': 'gini', 'max_depth': 28}. Best is trial 19 with value: -0.5105451117618671.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:19,531]\u001b[0m Trial 94 finished with value: -0.5107613854605699 and parameters: {'criterion': 'gini', 'max_depth': 25}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:19,658]\u001b[0m Trial 95 finished with value: -0.5080104303882194 and parameters: {'criterion': 'gini', 'max_depth': 34}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:19,791]\u001b[0m Trial 96 finished with value: -0.4965328231060374 and parameters: {'criterion': 'gini', 'max_depth': 22}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:19,916]\u001b[0m Trial 97 finished with value: -0.5094019074798564 and parameters: {'criterion': 'gini', 'max_depth': 36}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:20,048]\u001b[0m Trial 98 finished with value: -0.5008164055661238 and parameters: {'criterion': 'gini', 'max_depth': 33}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:20,175]\u001b[0m Trial 99 finished with value: -0.500757999424159 and parameters: {'criterion': 'gini', 'max_depth': 34}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:20,307]\u001b[0m Trial 100 finished with value: -0.49941543403265054 and parameters: {'criterion': 'gini', 'max_depth': 36}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:20,441]\u001b[0m Trial 101 finished with value: -0.5065570881767603 and parameters: {'criterion': 'gini', 'max_depth': 31}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:20,571]\u001b[0m Trial 102 finished with value: -0.5036513885442304 and parameters: {'criterion': 'gini', 'max_depth': 27}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:20,703]\u001b[0m Trial 103 finished with value: -0.5008380946083524 and parameters: {'criterion': 'gini', 'max_depth': 30}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:20,829]\u001b[0m Trial 104 finished with value: -0.506531216853149 and parameters: {'criterion': 'gini', 'max_depth': 32}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:20,964]\u001b[0m Trial 105 finished with value: -0.5064588968194041 and parameters: {'criterion': 'gini', 'max_depth': 36}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:21,093]\u001b[0m Trial 106 finished with value: -0.5036748747620449 and parameters: {'criterion': 'gini', 'max_depth': 28}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:21,231]\u001b[0m Trial 107 finished with value: -0.5051322613963595 and parameters: {'criterion': 'gini', 'max_depth': 26}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:21,361]\u001b[0m Trial 108 finished with value: -0.5036242769144635 and parameters: {'criterion': 'gini', 'max_depth': 29}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:21,504]\u001b[0m Trial 109 finished with value: -0.5090992028597313 and parameters: {'criterion': 'entropy', 'max_depth': 57}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:21,661]\u001b[0m Trial 110 finished with value: -0.5063287309435232 and parameters: {'criterion': 'entropy', 'max_depth': 61}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:21,797]\u001b[0m Trial 111 finished with value: -0.5006575319048749 and parameters: {'criterion': 'entropy', 'max_depth': 55}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:21,936]\u001b[0m Trial 112 finished with value: -0.504847133065941 and parameters: {'criterion': 'entropy', 'max_depth': 57}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:22,074]\u001b[0m Trial 113 finished with value: -0.49919473816860804 and parameters: {'criterion': 'entropy', 'max_depth': 51}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:22,219]\u001b[0m Trial 114 finished with value: -0.5006017254136992 and parameters: {'criterion': 'entropy', 'max_depth': 63}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:22,346]\u001b[0m Trial 115 finished with value: -0.5007942211905554 and parameters: {'criterion': 'gini', 'max_depth': 53}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:22,499]\u001b[0m Trial 116 finished with value: -0.5005897725490279 and parameters: {'criterion': 'entropy', 'max_depth': 58}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:22,632]\u001b[0m Trial 117 finished with value: -0.5022360737579413 and parameters: {'criterion': 'gini', 'max_depth': 33}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:22,776]\u001b[0m Trial 118 finished with value: -0.50916895458828 and parameters: {'criterion': 'entropy', 'max_depth': 49}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:22,917]\u001b[0m Trial 119 finished with value: -0.5006185703262475 and parameters: {'criterion': 'entropy', 'max_depth': 45}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:23,086]\u001b[0m Trial 120 finished with value: -0.5063370612421447 and parameters: {'criterion': 'entropy', 'max_depth': 47}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:23,229]\u001b[0m Trial 121 finished with value: -0.503498580217589 and parameters: {'criterion': 'entropy', 'max_depth': 48}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:23,364]\u001b[0m Trial 122 finished with value: -0.5034410840949548 and parameters: {'criterion': 'entropy', 'max_depth': 50}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:23,509]\u001b[0m Trial 123 finished with value: -0.5034804942896923 and parameters: {'criterion': 'entropy', 'max_depth': 31}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:23,648]\u001b[0m Trial 124 finished with value: -0.4885068678155088 and parameters: {'criterion': 'entropy', 'max_depth': 25}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:23,785]\u001b[0m Trial 125 finished with value: -0.5007606678347594 and parameters: {'criterion': 'gini', 'max_depth': 29}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:23,922]\u001b[0m Trial 126 finished with value: -0.5077400611217898 and parameters: {'criterion': 'entropy', 'max_depth': 53}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:24,050]\u001b[0m Trial 127 finished with value: -0.5022210915932215 and parameters: {'criterion': 'gini', 'max_depth': 42}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:24,181]\u001b[0m Trial 128 finished with value: -0.5033481972201775 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:24,316]\u001b[0m Trial 129 finished with value: -0.493678603416572 and parameters: {'criterion': 'gini', 'max_depth': 23}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:24,458]\u001b[0m Trial 130 finished with value: -0.509164578885131 and parameters: {'criterion': 'entropy', 'max_depth': 31}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:24,593]\u001b[0m Trial 131 finished with value: -0.5005942071433516 and parameters: {'criterion': 'entropy', 'max_depth': 31}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:24,738]\u001b[0m Trial 132 finished with value: -0.4966917649077617 and parameters: {'criterion': 'entropy', 'max_depth': 27}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:24,874]\u001b[0m Trial 133 finished with value: -0.5033835488724386 and parameters: {'criterion': 'entropy', 'max_depth': 34}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:25,012]\u001b[0m Trial 134 finished with value: -0.5006229989646237 and parameters: {'criterion': 'entropy', 'max_depth': 30}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:25,150]\u001b[0m Trial 135 finished with value: -0.502016646097235 and parameters: {'criterion': 'entropy', 'max_depth': 32}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:25,288]\u001b[0m Trial 136 finished with value: -0.5022479984034316 and parameters: {'criterion': 'gini', 'max_depth': 29}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:25,427]\u001b[0m Trial 137 finished with value: -0.5019922445460122 and parameters: {'criterion': 'entropy', 'max_depth': 49}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:25,571]\u001b[0m Trial 138 finished with value: -0.5050801156174465 and parameters: {'criterion': 'gini', 'max_depth': 33}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:25,711]\u001b[0m Trial 139 finished with value: -0.505142136821231 and parameters: {'criterion': 'gini', 'max_depth': 28}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:25,848]\u001b[0m Trial 140 finished with value: -0.5091301907207376 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:25,983]\u001b[0m Trial 141 finished with value: -0.509174981180599 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:26,121]\u001b[0m Trial 142 finished with value: -0.5033864062086416 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:26,258]\u001b[0m Trial 143 finished with value: -0.5019815252999941 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:26,400]\u001b[0m Trial 144 finished with value: -0.5105674144858496 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:26,543]\u001b[0m Trial 145 finished with value: -0.5063339716101734 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:26,690]\u001b[0m Trial 146 finished with value: -0.502016288980016 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:26,829]\u001b[0m Trial 147 finished with value: -0.5077815913758082 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:26,963]\u001b[0m Trial 148 finished with value: -0.49922740408817645 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:27,109]\u001b[0m Trial 149 finished with value: -0.5077180492271565 and parameters: {'criterion': 'entropy', 'max_depth': 42}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:27,246]\u001b[0m Trial 150 finished with value: -0.5035205258243527 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:27,387]\u001b[0m Trial 151 finished with value: -0.5091179084630535 and parameters: {'criterion': 'entropy', 'max_depth': 34}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:27,535]\u001b[0m Trial 152 finished with value: -0.5062877166602712 and parameters: {'criterion': 'entropy', 'max_depth': 34}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:27,675]\u001b[0m Trial 153 finished with value: -0.5077250715603746 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:27,816]\u001b[0m Trial 154 finished with value: -0.5106205136732943 and parameters: {'criterion': 'entropy', 'max_depth': 33}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:27,954]\u001b[0m Trial 155 finished with value: -0.5063144811665647 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:28,103]\u001b[0m Trial 156 finished with value: -0.5076674443027488 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:28,244]\u001b[0m Trial 157 finished with value: -0.5006487331617031 and parameters: {'criterion': 'entropy', 'max_depth': 33}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:28,377]\u001b[0m Trial 158 finished with value: -0.5034951807522706 and parameters: {'criterion': 'entropy', 'max_depth': 44}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:28,522]\u001b[0m Trial 159 finished with value: -0.5034727064220362 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:28,659]\u001b[0m Trial 160 finished with value: -0.5092208212238584 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 94 with value: -0.5107613854605699.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:28,807]\u001b[0m Trial 161 finished with value: -0.5134551335782349 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 161 with value: -0.5134551335782349.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:28,947]\u001b[0m Trial 162 finished with value: -0.5049183122253351 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 161 with value: -0.5134551335782349.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:29,090]\u001b[0m Trial 163 finished with value: -0.5134978783911692 and parameters: {'criterion': 'entropy', 'max_depth': 56}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:29,274]\u001b[0m Trial 164 finished with value: -0.5063000399948037 and parameters: {'criterion': 'entropy', 'max_depth': 55}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:29,420]\u001b[0m Trial 165 finished with value: -0.5005439712480573 and parameters: {'criterion': 'entropy', 'max_depth': 52}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:29,572]\u001b[0m Trial 166 finished with value: -0.501964034983376 and parameters: {'criterion': 'entropy', 'max_depth': 47}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:29,718]\u001b[0m Trial 167 finished with value: -0.5063513713510257 and parameters: {'criterion': 'entropy', 'max_depth': 60}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:29,857]\u001b[0m Trial 168 finished with value: -0.5048663475987003 and parameters: {'criterion': 'entropy', 'max_depth': 56}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:29,997]\u001b[0m Trial 169 finished with value: -0.4991625089182916 and parameters: {'criterion': 'entropy', 'max_depth': 57}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:30,132]\u001b[0m Trial 170 finished with value: -0.5048982804213142 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:30,276]\u001b[0m Trial 171 finished with value: -0.49917007368521693 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:30,418]\u001b[0m Trial 172 finished with value: -0.5049026424142269 and parameters: {'criterion': 'entropy', 'max_depth': 32}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:30,563]\u001b[0m Trial 173 finished with value: -0.5020136823064933 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:30,705]\u001b[0m Trial 174 finished with value: -0.506317940185243 and parameters: {'criterion': 'entropy', 'max_depth': 59}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:30,840]\u001b[0m Trial 175 finished with value: -0.5048875552193487 and parameters: {'criterion': 'entropy', 'max_depth': 51}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:30,981]\u001b[0m Trial 176 finished with value: -0.5019890495262889 and parameters: {'criterion': 'entropy', 'max_depth': 34}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:31,120]\u001b[0m Trial 177 finished with value: -0.5033835418497048 and parameters: {'criterion': 'entropy', 'max_depth': 62}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:31,231]\u001b[0m Trial 178 finished with value: -0.07447235806523078 and parameters: {'criterion': 'entropy', 'max_depth': 2}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:31,372]\u001b[0m Trial 179 finished with value: -0.5105810371906869 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:31,512]\u001b[0m Trial 180 finished with value: -0.5049149462615452 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:31,664]\u001b[0m Trial 181 finished with value: -0.5133976646435883 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:31,813]\u001b[0m Trial 182 finished with value: -0.5105479299981882 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:31,959]\u001b[0m Trial 183 finished with value: -0.5035057078691892 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:32,100]\u001b[0m Trial 184 finished with value: -0.5020301627051273 and parameters: {'criterion': 'entropy', 'max_depth': 41}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:32,237]\u001b[0m Trial 185 finished with value: -0.502034592784252 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:32,371]\u001b[0m Trial 186 finished with value: -0.5062924752278785 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:32,515]\u001b[0m Trial 187 finished with value: -0.5020939822053767 and parameters: {'criterion': 'entropy', 'max_depth': 43}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:32,666]\u001b[0m Trial 188 finished with value: -0.5034514597015057 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:32,810]\u001b[0m Trial 189 finished with value: -0.5033911393866033 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:32,952]\u001b[0m Trial 190 finished with value: -0.5090841138665112 and parameters: {'criterion': 'entropy', 'max_depth': 49}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:33,092]\u001b[0m Trial 191 finished with value: -0.5034876900275045 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:33,239]\u001b[0m Trial 192 finished with value: -0.5106429619516974 and parameters: {'criterion': 'entropy', 'max_depth': 33}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:33,382]\u001b[0m Trial 193 finished with value: -0.506304363245428 and parameters: {'criterion': 'entropy', 'max_depth': 34}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:33,526]\u001b[0m Trial 194 finished with value: -0.5019951148608962 and parameters: {'criterion': 'entropy', 'max_depth': 33}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:33,677]\u001b[0m Trial 195 finished with value: -0.5020485711655598 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:33,817]\u001b[0m Trial 196 finished with value: -0.5106141973184128 and parameters: {'criterion': 'entropy', 'max_depth': 41}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:33,962]\u001b[0m Trial 197 finished with value: -0.500601758557634 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:34,102]\u001b[0m Trial 198 finished with value: -0.5005985106026836 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:34,245]\u001b[0m Trial 199 finished with value: -0.5076966368563212 and parameters: {'criterion': 'entropy', 'max_depth': 41}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:34,387]\u001b[0m Trial 200 finished with value: -0.5048724132909014 and parameters: {'criterion': 'entropy', 'max_depth': 42}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:34,534]\u001b[0m Trial 201 finished with value: -0.5091750139669403 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:34,679]\u001b[0m Trial 202 finished with value: -0.5062956642916547 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:34,821]\u001b[0m Trial 203 finished with value: -0.5035013790202114 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:34,968]\u001b[0m Trial 204 finished with value: -0.5005916004698288 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:35,105]\u001b[0m Trial 205 finished with value: -0.49915924798466005 and parameters: {'criterion': 'entropy', 'max_depth': 32}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:35,247]\u001b[0m Trial 206 finished with value: -0.5077614929263239 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:35,386]\u001b[0m Trial 207 finished with value: -0.5063212339052159 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:35,530]\u001b[0m Trial 208 finished with value: -0.5077178113330346 and parameters: {'criterion': 'entropy', 'max_depth': 41}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:35,677]\u001b[0m Trial 209 finished with value: -0.5091708824714539 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:35,820]\u001b[0m Trial 210 finished with value: -0.49914860098245895 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:35,956]\u001b[0m Trial 211 finished with value: -0.5077360886584756 and parameters: {'criterion': 'entropy', 'max_depth': 33}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:36,100]\u001b[0m Trial 212 finished with value: -0.5048909144486285 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:36,241]\u001b[0m Trial 213 finished with value: -0.4963577293162711 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:36,382]\u001b[0m Trial 214 finished with value: -0.5019974978523456 and parameters: {'criterion': 'entropy', 'max_depth': 32}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:36,524]\u001b[0m Trial 215 finished with value: -0.507767677841622 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:36,665]\u001b[0m Trial 216 finished with value: -0.5062888784090686 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:36,821]\u001b[0m Trial 217 finished with value: -0.5020093527259601 and parameters: {'criterion': 'entropy', 'max_depth': 45}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:36,959]\u001b[0m Trial 218 finished with value: -0.5106751524597254 and parameters: {'criterion': 'entropy', 'max_depth': 48}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:37,101]\u001b[0m Trial 219 finished with value: -0.5034586930984515 and parameters: {'criterion': 'entropy', 'max_depth': 49}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:37,241]\u001b[0m Trial 220 finished with value: -0.5048845579270784 and parameters: {'criterion': 'entropy', 'max_depth': 52}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:37,381]\u001b[0m Trial 221 finished with value: -0.5034805274336274 and parameters: {'criterion': 'entropy', 'max_depth': 48}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:37,525]\u001b[0m Trial 222 finished with value: -0.5006104578853691 and parameters: {'criterion': 'entropy', 'max_depth': 50}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:37,668]\u001b[0m Trial 223 finished with value: -0.5034802634346722 and parameters: {'criterion': 'entropy', 'max_depth': 47}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:37,818]\u001b[0m Trial 224 finished with value: -0.509144672433129 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:37,954]\u001b[0m Trial 225 finished with value: -0.5005501629601126 and parameters: {'criterion': 'entropy', 'max_depth': 46}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:38,098]\u001b[0m Trial 226 finished with value: -0.5091812584355984 and parameters: {'criterion': 'entropy', 'max_depth': 34}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:38,233]\u001b[0m Trial 227 finished with value: -0.49488228880840585 and parameters: {'criterion': 'entropy', 'max_depth': 31}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:38,373]\u001b[0m Trial 228 finished with value: -0.5006275258986483 and parameters: {'criterion': 'entropy', 'max_depth': 33}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:38,514]\u001b[0m Trial 229 finished with value: -0.5035360036379782 and parameters: {'criterion': 'entropy', 'max_depth': 30}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:38,656]\u001b[0m Trial 230 finished with value: -0.5020044281504543 and parameters: {'criterion': 'entropy', 'max_depth': 34}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:38,810]\u001b[0m Trial 231 finished with value: -0.5048790927189489 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:38,949]\u001b[0m Trial 232 finished with value: -0.5006336247347845 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:39,096]\u001b[0m Trial 233 finished with value: -0.5006017056224069 and parameters: {'criterion': 'entropy', 'max_depth': 34}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:39,235]\u001b[0m Trial 234 finished with value: -0.5034618881181749 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:39,406]\u001b[0m Trial 235 finished with value: -0.43665306104348794 and parameters: {'criterion': 'entropy', 'max_depth': 17}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:39,566]\u001b[0m Trial 236 finished with value: -0.5106159535953347 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:39,704]\u001b[0m Trial 237 finished with value: -0.5034015283457967 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:39,849]\u001b[0m Trial 238 finished with value: -0.5034247614830819 and parameters: {'criterion': 'entropy', 'max_depth': 54}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:39,983]\u001b[0m Trial 239 finished with value: -0.49915299791764856 and parameters: {'criterion': 'entropy', 'max_depth': 43}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:40,125]\u001b[0m Trial 240 finished with value: -0.49913084678213526 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:40,263]\u001b[0m Trial 241 finished with value: -0.5078282364082397 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:40,412]\u001b[0m Trial 242 finished with value: -0.5062753018268473 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:40,551]\u001b[0m Trial 243 finished with value: -0.5034554995194764 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:40,699]\u001b[0m Trial 244 finished with value: -0.5091628172522001 and parameters: {'criterion': 'entropy', 'max_depth': 32}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:40,842]\u001b[0m Trial 245 finished with value: -0.5006247076623274 and parameters: {'criterion': 'entropy', 'max_depth': 31}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:40,983]\u001b[0m Trial 246 finished with value: -0.5048906821528603 and parameters: {'criterion': 'entropy', 'max_depth': 50}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:41,122]\u001b[0m Trial 247 finished with value: -0.5049022793410608 and parameters: {'criterion': 'entropy', 'max_depth': 32}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:41,264]\u001b[0m Trial 248 finished with value: -0.5048938712166364 and parameters: {'criterion': 'entropy', 'max_depth': 33}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:41,407]\u001b[0m Trial 249 finished with value: -0.49920636850074357 and parameters: {'criterion': 'entropy', 'max_depth': 48}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:41,549]\u001b[0m Trial 250 finished with value: -0.5063223095748512 and parameters: {'criterion': 'entropy', 'max_depth': 30}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:41,690]\u001b[0m Trial 251 finished with value: -0.4963293281137462 and parameters: {'criterion': 'entropy', 'max_depth': 41}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:41,837]\u001b[0m Trial 252 finished with value: -0.5049057380021456 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:41,973]\u001b[0m Trial 253 finished with value: -0.4991305827831803 and parameters: {'criterion': 'entropy', 'max_depth': 34}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:42,125]\u001b[0m Trial 254 finished with value: -0.5048979367818467 and parameters: {'criterion': 'entropy', 'max_depth': 51}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:42,278]\u001b[0m Trial 255 finished with value: -0.4992171134940014 and parameters: {'criterion': 'entropy', 'max_depth': 33}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:42,427]\u001b[0m Trial 256 finished with value: -0.5034618218303051 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:42,565]\u001b[0m Trial 257 finished with value: -0.4949156871878472 and parameters: {'criterion': 'entropy', 'max_depth': 31}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:42,712]\u001b[0m Trial 258 finished with value: -0.5020314368644108 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:42,863]\u001b[0m Trial 259 finished with value: -0.46261618068530935 and parameters: {'criterion': 'entropy', 'max_depth': 20}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:43,001]\u001b[0m Trial 260 finished with value: -0.5020569832212695 and parameters: {'criterion': 'entropy', 'max_depth': 29}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:43,147]\u001b[0m Trial 261 finished with value: -0.511991284302623 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:43,289]\u001b[0m Trial 262 finished with value: -0.49921352189958323 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:43,432]\u001b[0m Trial 263 finished with value: -0.5063223744219729 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:43,577]\u001b[0m Trial 264 finished with value: -0.5020444396700733 and parameters: {'criterion': 'entropy', 'max_depth': 34}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:43,724]\u001b[0m Trial 265 finished with value: -0.5091355234224975 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:43,875]\u001b[0m Trial 266 finished with value: -0.5063220459334901 and parameters: {'criterion': 'entropy', 'max_depth': 46}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:44,018]\u001b[0m Trial 267 finished with value: -0.51057670058742 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:44,160]\u001b[0m Trial 268 finished with value: -0.5006648312320972 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:44,302]\u001b[0m Trial 269 finished with value: -0.5034381865920831 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:44,446]\u001b[0m Trial 270 finished with value: -0.501986673592537 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:44,585]\u001b[0m Trial 271 finished with value: -0.5006360606428653 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:44,723]\u001b[0m Trial 272 finished with value: -0.502002705375061 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:44,875]\u001b[0m Trial 273 finished with value: -0.5019772940151092 and parameters: {'criterion': 'entropy', 'max_depth': 43}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:45,013]\u001b[0m Trial 274 finished with value: -0.3113915245085212 and parameters: {'criterion': 'entropy', 'max_depth': 13}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:45,153]\u001b[0m Trial 275 finished with value: -0.5034546610347699 and parameters: {'criterion': 'entropy', 'max_depth': 42}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:45,292]\u001b[0m Trial 276 finished with value: -0.5034682442821313 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:45,441]\u001b[0m Trial 277 finished with value: -0.5048872308884711 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:45,583]\u001b[0m Trial 278 finished with value: -0.4977294900908869 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:45,723]\u001b[0m Trial 279 finished with value: -0.5049376972811918 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:45,875]\u001b[0m Trial 280 finished with value: -0.50631166257265 and parameters: {'criterion': 'entropy', 'max_depth': 41}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:46,013]\u001b[0m Trial 281 finished with value: -0.5020558317504934 and parameters: {'criterion': 'entropy', 'max_depth': 50}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:46,156]\u001b[0m Trial 282 finished with value: -0.5034561928794672 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:46,298]\u001b[0m Trial 283 finished with value: -0.5076783288944802 and parameters: {'criterion': 'entropy', 'max_depth': 53}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:46,447]\u001b[0m Trial 284 finished with value: -0.5020966877107661 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:46,586]\u001b[0m Trial 285 finished with value: -0.49773234742708994 and parameters: {'criterion': 'entropy', 'max_depth': 48}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:46,726]\u001b[0m Trial 286 finished with value: -0.5048437421334744 and parameters: {'criterion': 'entropy', 'max_depth': 34}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:46,880]\u001b[0m Trial 287 finished with value: -0.5005670004759655 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:47,018]\u001b[0m Trial 288 finished with value: -0.5020636214164915 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:47,160]\u001b[0m Trial 289 finished with value: -0.49494754145310316 and parameters: {'criterion': 'entropy', 'max_depth': 33}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:47,300]\u001b[0m Trial 290 finished with value: -0.5063362294225784 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:47,438]\u001b[0m Trial 291 finished with value: -0.5034879868128006 and parameters: {'criterion': 'entropy', 'max_depth': 41}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:47,580]\u001b[0m Trial 292 finished with value: -0.5091114525096987 and parameters: {'criterion': 'entropy', 'max_depth': 44}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:47,728]\u001b[0m Trial 293 finished with value: -0.5077221084788257 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:47,875]\u001b[0m Trial 294 finished with value: -0.5034207749393363 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:48,019]\u001b[0m Trial 295 finished with value: -0.5077932608078257 and parameters: {'criterion': 'entropy', 'max_depth': 49}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:48,165]\u001b[0m Trial 296 finished with value: -0.5034921577657627 and parameters: {'criterion': 'entropy', 'max_depth': 52}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:48,306]\u001b[0m Trial 297 finished with value: -0.4977427769105457 and parameters: {'criterion': 'entropy', 'max_depth': 33}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:48,458]\u001b[0m Trial 298 finished with value: -0.5005805586912748 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:48,601]\u001b[0m Trial 299 finished with value: -0.5119948103183639 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:48,740]\u001b[0m Trial 300 finished with value: -0.4992035034102513 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:48,895]\u001b[0m Trial 301 finished with value: -0.5034482389345428 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:49,033]\u001b[0m Trial 302 finished with value: -0.5050949332150162 and parameters: {'criterion': 'gini', 'max_depth': 42}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:49,174]\u001b[0m Trial 303 finished with value: -0.5019687935509837 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:49,325]\u001b[0m Trial 304 finished with value: -0.5076643155708953 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:49,476]\u001b[0m Trial 305 finished with value: -0.5106280982315119 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:49,646]\u001b[0m Trial 306 finished with value: -0.5006092552383475 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:49,799]\u001b[0m Trial 307 finished with value: -0.5020470344317016 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:49,952]\u001b[0m Trial 308 finished with value: -0.5063508422699613 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:50,097]\u001b[0m Trial 309 finished with value: -0.5049408260130452 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:50,241]\u001b[0m Trial 310 finished with value: -0.5049309776864755 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:50,371]\u001b[0m Trial 311 finished with value: -0.503660123452345 and parameters: {'criterion': 'gini', 'max_depth': 42}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:50,513]\u001b[0m Trial 312 finished with value: -0.5019295077567276 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:50,655]\u001b[0m Trial 313 finished with value: -0.5063862013189178 and parameters: {'criterion': 'entropy', 'max_depth': 34}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:50,796]\u001b[0m Trial 314 finished with value: -0.5062725291454261 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:50,948]\u001b[0m Trial 315 finished with value: -0.20010248653353463 and parameters: {'criterion': 'entropy', 'max_depth': 10}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:51,090]\u001b[0m Trial 316 finished with value: -0.5077345899577133 and parameters: {'criterion': 'entropy', 'max_depth': 35}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:51,235]\u001b[0m Trial 317 finished with value: -0.5019955051220502 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:51,375]\u001b[0m Trial 318 finished with value: -0.4715871781700901 and parameters: {'criterion': 'entropy', 'max_depth': 22}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:51,512]\u001b[0m Trial 319 finished with value: -0.5022666358823777 and parameters: {'criterion': 'gini', 'max_depth': 41}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:51,655]\u001b[0m Trial 320 finished with value: -0.5092419879462827 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:51,796]\u001b[0m Trial 321 finished with value: -0.5048842942857172 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:51,939]\u001b[0m Trial 322 finished with value: -0.5034805274336274 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 163 with value: -0.5134978783911692.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:52,083]\u001b[0m Trial 323 finished with value: -0.5148395872443234 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:52,222]\u001b[0m Trial 324 finished with value: -0.5034630900336412 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:52,369]\u001b[0m Trial 325 finished with value: -0.4977288298748309 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:52,535]\u001b[0m Trial 326 finished with value: -0.5064344098992334 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:52,686]\u001b[0m Trial 327 finished with value: -0.49654749722528735 and parameters: {'criterion': 'gini', 'max_depth': 37}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:52,826]\u001b[0m Trial 328 finished with value: -0.5006052172187188 and parameters: {'criterion': 'entropy', 'max_depth': 41}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:52,977]\u001b[0m Trial 329 finished with value: -0.5034364447504445 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:53,114]\u001b[0m Trial 330 finished with value: -0.5048803005903624 and parameters: {'criterion': 'entropy', 'max_depth': 64}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:53,255]\u001b[0m Trial 331 finished with value: -0.5048831325369196 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:53,399]\u001b[0m Trial 332 finished with value: -0.49631112374131536 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:53,542]\u001b[0m Trial 333 finished with value: -0.5077899998741942 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:53,691]\u001b[0m Trial 334 finished with value: -0.5048587570845355 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:53,826]\u001b[0m Trial 335 finished with value: -0.5051222121262192 and parameters: {'criterion': 'gini', 'max_depth': 34}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:53,968]\u001b[0m Trial 336 finished with value: -0.4871039789219692 and parameters: {'criterion': 'entropy', 'max_depth': 25}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:54,119]\u001b[0m Trial 337 finished with value: -0.503466482406856 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:54,267]\u001b[0m Trial 338 finished with value: -0.5049289923714712 and parameters: {'criterion': 'entropy', 'max_depth': 42}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:54,407]\u001b[0m Trial 339 finished with value: -0.4963023253557372 and parameters: {'criterion': 'entropy', 'max_depth': 58}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:54,555]\u001b[0m Trial 340 finished with value: -0.5049417300764286 and parameters: {'criterion': 'entropy', 'max_depth': 36}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:54,698]\u001b[0m Trial 341 finished with value: -0.5077816304756904 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:54,853]\u001b[0m Trial 342 finished with value: -0.506321167617346 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:54,985]\u001b[0m Trial 343 finished with value: -0.5022500870815261 and parameters: {'criterion': 'gini', 'max_depth': 33}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:55,129]\u001b[0m Trial 344 finished with value: -0.5105735133219858 and parameters: {'criterion': 'entropy', 'max_depth': 55}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:55,279]\u001b[0m Trial 345 finished with value: -0.49914892531333654 and parameters: {'criterion': 'entropy', 'max_depth': 59}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:55,423]\u001b[0m Trial 346 finished with value: -0.5105691044749017 and parameters: {'criterion': 'entropy', 'max_depth': 54}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:55,568]\u001b[0m Trial 347 finished with value: -0.5106022057114532 and parameters: {'criterion': 'entropy', 'max_depth': 56}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:55,718]\u001b[0m Trial 348 finished with value: -0.5120386625041204 and parameters: {'criterion': 'entropy', 'max_depth': 55}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:55,864]\u001b[0m Trial 349 finished with value: -0.5048758917432783 and parameters: {'criterion': 'entropy', 'max_depth': 55}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:56,020]\u001b[0m Trial 350 finished with value: -0.5020636214164915 and parameters: {'criterion': 'entropy', 'max_depth': 54}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:56,165]\u001b[0m Trial 351 finished with value: -0.49917316187644 and parameters: {'criterion': 'entropy', 'max_depth': 55}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:56,312]\u001b[0m Trial 352 finished with value: -0.49629915752400144 and parameters: {'criterion': 'entropy', 'max_depth': 57}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:56,461]\u001b[0m Trial 353 finished with value: -0.5079785814053113 and parameters: {'criterion': 'gini', 'max_depth': 56}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:56,609]\u001b[0m Trial 354 finished with value: -0.5034288542362797 and parameters: {'criterion': 'entropy', 'max_depth': 54}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:56,753]\u001b[0m Trial 355 finished with value: -0.5063407574927595 and parameters: {'criterion': 'entropy', 'max_depth': 57}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:56,895]\u001b[0m Trial 356 finished with value: -0.5019623710991573 and parameters: {'criterion': 'entropy', 'max_depth': 56}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:57,043]\u001b[0m Trial 357 finished with value: -0.5063476546469332 and parameters: {'criterion': 'entropy', 'max_depth': 55}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:57,196]\u001b[0m Trial 358 finished with value: -0.5006001080260579 and parameters: {'criterion': 'entropy', 'max_depth': 53}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:57,347]\u001b[0m Trial 359 finished with value: -0.49772473152327945 and parameters: {'criterion': 'entropy', 'max_depth': 54}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:57,486]\u001b[0m Trial 360 finished with value: -0.5091996668960308 and parameters: {'criterion': 'entropy', 'max_depth': 56}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:57,624]\u001b[0m Trial 361 finished with value: -0.4964942893728363 and parameters: {'criterion': 'gini', 'max_depth': 58}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:57,772]\u001b[0m Trial 362 finished with value: -0.5048790867630017 and parameters: {'criterion': 'entropy', 'max_depth': 53}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:57,920]\u001b[0m Trial 363 finished with value: -0.507777162737432 and parameters: {'criterion': 'entropy', 'max_depth': 57}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:58,067]\u001b[0m Trial 364 finished with value: -0.5006276383091341 and parameters: {'criterion': 'entropy', 'max_depth': 60}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:58,217]\u001b[0m Trial 365 finished with value: -0.504930173054897 and parameters: {'criterion': 'entropy', 'max_depth': 55}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:58,360]\u001b[0m Trial 366 finished with value: -0.5006347592955942 and parameters: {'criterion': 'entropy', 'max_depth': 52}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:58,510]\u001b[0m Trial 367 finished with value: -0.5035120242240707 and parameters: {'criterion': 'entropy', 'max_depth': 54}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:58,654]\u001b[0m Trial 368 finished with value: -0.5005559255534766 and parameters: {'criterion': 'entropy', 'max_depth': 58}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:58,791]\u001b[0m Trial 369 finished with value: -0.5007589094434896 and parameters: {'criterion': 'gini', 'max_depth': 55}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:58,939]\u001b[0m Trial 370 finished with value: -0.5020987150257448 and parameters: {'criterion': 'entropy', 'max_depth': 56}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:59,086]\u001b[0m Trial 371 finished with value: -0.5048373193240544 and parameters: {'criterion': 'entropy', 'max_depth': 56}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:59,345]\u001b[0m Trial 372 finished with value: -0.49918955041858937 and parameters: {'criterion': 'entropy', 'max_depth': 41}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:59,495]\u001b[0m Trial 373 finished with value: -0.5020528690265383 and parameters: {'criterion': 'entropy', 'max_depth': 44}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:59,638]\u001b[0m Trial 374 finished with value: -0.49773555542549425 and parameters: {'criterion': 'entropy', 'max_depth': 52}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:59,805]\u001b[0m Trial 375 finished with value: -0.5049333938218598 and parameters: {'criterion': 'entropy', 'max_depth': 54}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:45:59,958]\u001b[0m Trial 376 finished with value: -0.4963656497596669 and parameters: {'criterion': 'entropy', 'max_depth': 51}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:00,104]\u001b[0m Trial 377 finished with value: -0.4979595953296676 and parameters: {'criterion': 'gini', 'max_depth': 39}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:00,250]\u001b[0m Trial 378 finished with value: -0.5048786961442542 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:00,391]\u001b[0m Trial 379 finished with value: -0.5005984704360148 and parameters: {'criterion': 'entropy', 'max_depth': 57}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:00,537]\u001b[0m Trial 380 finished with value: -0.5019759878480473 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:00,684]\u001b[0m Trial 381 finished with value: -0.5106481106018341 and parameters: {'criterion': 'entropy', 'max_depth': 59}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:00,825]\u001b[0m Trial 382 finished with value: -0.5019954779340623 and parameters: {'criterion': 'entropy', 'max_depth': 56}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:00,970]\u001b[0m Trial 383 finished with value: -0.5091159468997266 and parameters: {'criterion': 'entropy', 'max_depth': 42}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:01,119]\u001b[0m Trial 384 finished with value: -0.5047985886004469 and parameters: {'criterion': 'entropy', 'max_depth': 41}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:01,266]\u001b[0m Trial 385 finished with value: -0.49510332548238056 and parameters: {'criterion': 'gini', 'max_depth': 43}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:01,406]\u001b[0m Trial 386 finished with value: -0.503365271189404 and parameters: {'criterion': 'entropy', 'max_depth': 59}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:01,566]\u001b[0m Trial 387 finished with value: -0.49912736201621744 and parameters: {'criterion': 'entropy', 'max_depth': 60}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:01,709]\u001b[0m Trial 388 finished with value: -0.5005378138783405 and parameters: {'criterion': 'entropy', 'max_depth': 61}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:01,854]\u001b[0m Trial 389 finished with value: -0.5091932905831883 and parameters: {'criterion': 'entropy', 'max_depth': 61}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:01,996]\u001b[0m Trial 390 finished with value: -0.5048253259187528 and parameters: {'criterion': 'entropy', 'max_depth': 58}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:02,147]\u001b[0m Trial 391 finished with value: -0.49769129999990297 and parameters: {'criterion': 'entropy', 'max_depth': 54}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:02,292]\u001b[0m Trial 392 finished with value: -0.5034255329707256 and parameters: {'criterion': 'entropy', 'max_depth': 53}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:02,431]\u001b[0m Trial 393 finished with value: -0.5022233776248075 and parameters: {'criterion': 'gini', 'max_depth': 59}. Best is trial 323 with value: -0.5148395872443234.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:02,585]\u001b[0m Trial 394 finished with value: -0.5177470503081261 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:02,741]\u001b[0m Trial 395 finished with value: -0.5063965497374807 and parameters: {'criterion': 'entropy', 'max_depth': 57}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:02,903]\u001b[0m Trial 396 finished with value: -0.4516377377399176 and parameters: {'criterion': 'entropy', 'max_depth': 18}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:03,022]\u001b[0m Trial 397 finished with value: -0.056344275332497994 and parameters: {'criterion': 'entropy', 'max_depth': 3}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:03,175]\u001b[0m Trial 398 finished with value: -0.5005808480798757 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:03,322]\u001b[0m Trial 399 finished with value: -0.5019974587524635 and parameters: {'criterion': 'entropy', 'max_depth': 40}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:03,468]\u001b[0m Trial 400 finished with value: -0.5062889175089508 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:03,608]\u001b[0m Trial 401 finished with value: -0.3608731047490096 and parameters: {'criterion': 'entropy', 'max_depth': 14}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:03,762]\u001b[0m Trial 402 finished with value: -0.5063343015394046 and parameters: {'criterion': 'entropy', 'max_depth': 56}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:03,897]\u001b[0m Trial 403 finished with value: -0.5050675758117297 and parameters: {'criterion': 'gini', 'max_depth': 43}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:04,044]\u001b[0m Trial 404 finished with value: -0.5020183360862871 and parameters: {'criterion': 'entropy', 'max_depth': 41}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:04,195]\u001b[0m Trial 405 finished with value: -0.49916714124006833 and parameters: {'criterion': 'entropy', 'max_depth': 39}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:04,342]\u001b[0m Trial 406 finished with value: -0.5033984994033417 and parameters: {'criterion': 'entropy', 'max_depth': 37}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:04,491]\u001b[0m Trial 407 finished with value: -0.5020258934565167 and parameters: {'criterion': 'entropy', 'max_depth': 62}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:04,645]\u001b[0m Trial 408 finished with value: -0.5077238316118126 and parameters: {'criterion': 'entropy', 'max_depth': 58}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:04,794]\u001b[0m Trial 409 finished with value: -0.5049960974672094 and parameters: {'criterion': 'entropy', 'max_depth': 51}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:04,931]\u001b[0m Trial 410 finished with value: -0.5065541952246809 and parameters: {'criterion': 'gini', 'max_depth': 55}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:05,076]\u001b[0m Trial 411 finished with value: -0.500568664717778 and parameters: {'criterion': 'entropy', 'max_depth': 53}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n",
            "\u001b[32m[I 2021-10-03 12:46:05,230]\u001b[0m Trial 412 finished with value: -0.4963598155224241 and parameters: {'criterion': 'entropy', 'max_depth': 38}. Best is trial 394 with value: -0.5177470503081261.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params: {'criterion': 'entropy', 'max_depth': 39}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zGOi_NqfEuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb7e75e-d0d6-4dd4-ce46-55d3dff25eb3"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#ハイパーパラメータチューニングで特定した値を設定\n",
        "\n",
        "# 訓練の実施\n",
        "model = DecisionTreeClassifier(\n",
        "    criterion = study.best_params['criterion'],\n",
        "    max_depth = study.best_params['max_depth']\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "# 正解率と混同行列の出力\n",
        "print(\"Accurary: {:.5f} %\".format(100 * accuracy_score(y_test, pred)))\n",
        "print(confusion_matrix(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accurary: 98.29244 %\n",
            "[[3813   34]\n",
            " [  69 2116]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEju7b-_s3ao"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# データセットを再ロードする\n",
        "df = pd.read_csv('./HttpParamsDataset/payload_train.csv')\n",
        "test_data = pd.read_csv('./HttpParamsDataset/payload_test.csv')\n",
        "\n",
        "train_rows = ((df.attack_type == 'norm') | (df.attack_type == 'sqli'))\n",
        "df = df[train_rows]\n",
        "\n",
        "test_train_rows = ((test_data.attack_type == 'norm') | (test_data.attack_type == 'sqli'))\n",
        "test_data = test_data[test_train_rows]\n",
        "\n",
        "df_y = df[['label']]\n",
        "test_y = test_data[['label']]\n",
        "\n",
        "df_x = df.iloc[:,:-1]\n",
        "test_x = test_data.iloc[:,:-1]\n",
        "\n",
        "X_all = pd.concat([df_x, test_x])\n",
        "y_all = pd.concat([df_y, test_y])\n",
        "\n",
        "rep = y_all.label.replace({\"norm\":0,\"anom\":1})\n",
        "y_all = y_all.assign(label=rep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HE2kGXFQhGR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "02aef38d-9e57-4898-b684-b077adc488b7"
      },
      "source": [
        "X_all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>payload</th>\n",
              "      <th>length</th>\n",
              "      <th>attack_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c/ caridad s/n</td>\n",
              "      <td>14</td>\n",
              "      <td>norm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>campello, el</td>\n",
              "      <td>12</td>\n",
              "      <td>norm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1442431887503330</td>\n",
              "      <td>16</td>\n",
              "      <td>norm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nue37</td>\n",
              "      <td>5</td>\n",
              "      <td>norm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tufts3@joll.rs</td>\n",
              "      <td>14</td>\n",
              "      <td>norm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10176</th>\n",
              "      <td>1\") where 2367=2367;select (case when (4666=46...</td>\n",
              "      <td>113</td>\n",
              "      <td>sqli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10177</th>\n",
              "      <td>1') and updatexml(3393,concat(0x2e,0x7171706a7...</td>\n",
              "      <td>113</td>\n",
              "      <td>sqli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10178</th>\n",
              "      <td>1') as tqdg where 9355=9355;select (case when ...</td>\n",
              "      <td>136</td>\n",
              "      <td>sqli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10179</th>\n",
              "      <td>1') and extractvalue(7982,concat(0x5c,0x717170...</td>\n",
              "      <td>111</td>\n",
              "      <td>sqli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10180</th>\n",
              "      <td>1 rlike (select * from (select(sleep(5)))sgvo)...</td>\n",
              "      <td>53</td>\n",
              "      <td>sqli</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30156 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 payload  length attack_type\n",
              "0                                         c/ caridad s/n      14        norm\n",
              "1                                           campello, el      12        norm\n",
              "2                                       1442431887503330      16        norm\n",
              "3                                                  nue37       5        norm\n",
              "4                                         tufts3@joll.rs      14        norm\n",
              "...                                                  ...     ...         ...\n",
              "10176  1\") where 2367=2367;select (case when (4666=46...     113        sqli\n",
              "10177  1') and updatexml(3393,concat(0x2e,0x7171706a7...     113        sqli\n",
              "10178  1') as tqdg where 9355=9355;select (case when ...     136        sqli\n",
              "10179  1') and extractvalue(7982,concat(0x5c,0x717170...     111        sqli\n",
              "10180  1 rlike (select * from (select(sleep(5)))sgvo)...      53        sqli\n",
              "\n",
              "[30156 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl5JCNaktroh"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "X = X_all['payload']\n",
        "y = y_all\n",
        "\n",
        "# ベクトル化のためのオプションの設定、文字を対象にユニグラムを行う\n",
        "vec_opts = {\n",
        "    \"ngram_range\": (1, 1), \n",
        "    \"analyzer\": \"char\", \n",
        "    \"min_df\" : 0.1\n",
        "}\n",
        "\n",
        "# TfidfVectorizerの初期化\n",
        "v = TfidfVectorizer(**vec_opts)\n",
        "# ベクトル化の実行\n",
        "X = v.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9FAc5OVIPry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6efd4d4b-aabe-44c9-ad2a-6407695a3211"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 特徴に使用されている文字を出力\n",
        "features = v.get_feature_names()\n",
        "np.array(features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' ', '\"', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3',\n",
              "       '4', '5', '6', '7', '8', '9', '=', 'a', 'b', 'c', 'd', 'e', 'f',\n",
              "       'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u',\n",
              "       'v', 'w', 'x', 'y'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arzJeJ-BIRjI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "d6f4bf1e-83ba-45c1-c812-825daa1df807"
      },
      "source": [
        "df = pd.DataFrame(X.toarray())\n",
        "df.columns = features\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>\"</th>\n",
              "      <th>'</th>\n",
              "      <th>(</th>\n",
              "      <th>)</th>\n",
              "      <th>*</th>\n",
              "      <th>,</th>\n",
              "      <th>-</th>\n",
              "      <th>.</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>=</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "      <th>e</th>\n",
              "      <th>f</th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "      <th>i</th>\n",
              "      <th>k</th>\n",
              "      <th>l</th>\n",
              "      <th>m</th>\n",
              "      <th>n</th>\n",
              "      <th>o</th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>s</th>\n",
              "      <th>t</th>\n",
              "      <th>u</th>\n",
              "      <th>v</th>\n",
              "      <th>w</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.453262</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.367518</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.460722</td>\n",
              "      <td>0.504676</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.231185</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.213771</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.209315</td>\n",
              "      <td>0.222629</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.223881</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.297448</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.181529</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.227566</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.379535</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.637700</td>\n",
              "      <td>0.279457</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.211999</td>\n",
              "      <td>0.320803</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.316555</td>\n",
              "      <td>0.257108</td>\n",
              "      <td>0.154605</td>\n",
              "      <td>0.637142</td>\n",
              "      <td>0.493407</td>\n",
              "      <td>0.150187</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.165919</td>\n",
              "      <td>0.332115</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.488536</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.508881</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.342872</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.381555</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.489108</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.382917</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259419</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.310430</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.407889</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.203400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.198388</td>\n",
              "      <td>0.422014</td>\n",
              "      <td>0.443910</td>\n",
              "      <td>0.259723</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30151</th>\n",
              "      <td>0.427799</td>\n",
              "      <td>0.061067</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.132674</td>\n",
              "      <td>0.162360</td>\n",
              "      <td>0.062953</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.096652</td>\n",
              "      <td>0.117327</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064151</td>\n",
              "      <td>0.077151</td>\n",
              "      <td>0.079487</td>\n",
              "      <td>0.164146</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562813</td>\n",
              "      <td>0.082797</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.086371</td>\n",
              "      <td>0.133412</td>\n",
              "      <td>0.046812</td>\n",
              "      <td>0.100347</td>\n",
              "      <td>0.073281</td>\n",
              "      <td>0.390506</td>\n",
              "      <td>0.047558</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131508</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.093734</td>\n",
              "      <td>0.082153</td>\n",
              "      <td>0.093121</td>\n",
              "      <td>0.031161</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.091180</td>\n",
              "      <td>0.290938</td>\n",
              "      <td>0.170019</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100595</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.056381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30152</th>\n",
              "      <td>0.166014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.208435</td>\n",
              "      <td>0.267729</td>\n",
              "      <td>0.245725</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.264680</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.159385</td>\n",
              "      <td>0.323633</td>\n",
              "      <td>0.038922</td>\n",
              "      <td>0.360899</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.121685</td>\n",
              "      <td>0.375929</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.129710</td>\n",
              "      <td>0.087146</td>\n",
              "      <td>0.188453</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.101248</td>\n",
              "      <td>0.110907</td>\n",
              "      <td>0.140718</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100469</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.094575</td>\n",
              "      <td>0.041445</td>\n",
              "      <td>0.156594</td>\n",
              "      <td>0.031441</td>\n",
              "      <td>0.047577</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.032617</td>\n",
              "      <td>0.137235</td>\n",
              "      <td>0.040147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.369485</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30153</th>\n",
              "      <td>0.468956</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.049065</td>\n",
              "      <td>0.126046</td>\n",
              "      <td>0.154249</td>\n",
              "      <td>0.059808</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.055733</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030473</td>\n",
              "      <td>0.183243</td>\n",
              "      <td>0.075516</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142405</td>\n",
              "      <td>0.381927</td>\n",
              "      <td>0.196652</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.081423</td>\n",
              "      <td>0.082057</td>\n",
              "      <td>0.152097</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.190669</td>\n",
              "      <td>0.069620</td>\n",
              "      <td>0.397499</td>\n",
              "      <td>0.090365</td>\n",
              "      <td>0.047301</td>\n",
              "      <td>0.208231</td>\n",
              "      <td>0.063784</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.089051</td>\n",
              "      <td>0.117074</td>\n",
              "      <td>0.147448</td>\n",
              "      <td>0.088813</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.144375</td>\n",
              "      <td>0.245693</td>\n",
              "      <td>0.226136</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.095570</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30154</th>\n",
              "      <td>0.171542</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.215375</td>\n",
              "      <td>0.276644</td>\n",
              "      <td>0.253907</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.227911</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164692</td>\n",
              "      <td>0.234086</td>\n",
              "      <td>0.120653</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.039068</td>\n",
              "      <td>0.083825</td>\n",
              "      <td>0.517929</td>\n",
              "      <td>0.129590</td>\n",
              "      <td>0.134029</td>\n",
              "      <td>0.090048</td>\n",
              "      <td>0.222546</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.174366</td>\n",
              "      <td>0.152800</td>\n",
              "      <td>0.203565</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.121721</td>\n",
              "      <td>0.097724</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.097085</td>\n",
              "      <td>0.032488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031687</td>\n",
              "      <td>0.033703</td>\n",
              "      <td>0.177256</td>\n",
              "      <td>0.041484</td>\n",
              "      <td>0.188331</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.254525</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30155</th>\n",
              "      <td>0.401641</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.359845</td>\n",
              "      <td>0.330270</td>\n",
              "      <td>0.128058</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.196609</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065247</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076228</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.054277</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.136084</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.397181</td>\n",
              "      <td>0.096742</td>\n",
              "      <td>0.101277</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.068285</td>\n",
              "      <td>0.118747</td>\n",
              "      <td>0.254229</td>\n",
              "      <td>0.083557</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.126775</td>\n",
              "      <td>0.095920</td>\n",
              "      <td>0.123651</td>\n",
              "      <td>0.394549</td>\n",
              "      <td>0.138340</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.122486</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.124153</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30156 rows × 43 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        \"         '  ...         w         x         y\n",
              "0      0.453262  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "1      0.223881  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "2      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "3      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "4      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "...         ...       ...       ...  ...       ...       ...       ...\n",
              "30151  0.427799  0.061067  0.000000  ...  0.100595  0.000000  0.056381\n",
              "30152  0.166014  0.000000  0.208435  ...  0.000000  0.369485  0.000000\n",
              "30153  0.468956  0.000000  0.049065  ...  0.095570  0.000000  0.000000\n",
              "30154  0.171542  0.000000  0.215375  ...  0.000000  0.254525  0.000000\n",
              "30155  0.401641  0.000000  0.000000  ...  0.000000  0.124153  0.000000\n",
              "\n",
              "[30156 rows x 43 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1E1hlGvnULs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2163aaf1-3ee7-4f42-eaa9-e0cf8b0d18d8"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.model_selection import train_test_split\n",
        "import optuna.integration.lightgbm as olgb\n",
        "import optuna\n",
        "\n",
        "# データセットを訓練用とテスト用に分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=101)\n",
        "\n",
        "# LightGBM用のデータセットに変換\n",
        "train = olgb.Dataset(X_train, y_train)\n",
        "\n",
        "# パラメータの設定\n",
        "params = {\n",
        "    \"objective\": \"binary\",\n",
        "    \"metric\": \"binary_logloss\",\n",
        "    \"verbosity\": -1,\n",
        "    \"boosting_type\": \"gbdt\",\n",
        "}\n",
        "\n",
        "# 交差検証を使用したハイパーパラメータの探索\n",
        "tuner = olgb.LightGBMTunerCV(params, train, verbose_eval=100, early_stopping_rounds=100, folds=StratifiedKFold(n_splits=5))\n",
        "\n",
        "# ハイパーパラメータ探索の実行\n",
        "tuner.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:46:06,144]\u001b[0m A new study created in memory with name: no-name-61b6fe68-4772-470a-9389-e4e945da0c75\u001b[0m\n",
            "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00115086 + 0.000685716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "feature_fraction, val_score: 0.001096:  14%|#4        | 1/7 [00:05<00:31,  5.30s/it]\u001b[32m[I 2021-10-03 12:46:11,467]\u001b[0m Trial 0 finished with value: 0.001096440922652404 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.001096440922652404.\u001b[0m\n",
            "feature_fraction, val_score: 0.001096:  14%|#4        | 1/7 [00:05<00:31,  5.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00135099 + 0.000840922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "feature_fraction, val_score: 0.001096:  29%|##8       | 2/7 [00:10<00:27,  5.52s/it]\u001b[32m[I 2021-10-03 12:46:17,143]\u001b[0m Trial 1 finished with value: 0.0012709937076241882 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.001096440922652404.\u001b[0m\n",
            "feature_fraction, val_score: 0.001096:  29%|##8       | 2/7 [00:10<00:27,  5.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00235411 + 0.00137145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "feature_fraction, val_score: 0.001096:  43%|####2     | 3/7 [00:18<00:24,  6.23s/it]\u001b[32m[I 2021-10-03 12:46:24,216]\u001b[0m Trial 2 finished with value: 0.0022536931240183843 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.001096440922652404.\u001b[0m\n",
            "feature_fraction, val_score: 0.001096:  43%|####2     | 3/7 [00:18<00:24,  6.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00189494 + 0.00120489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "feature_fraction, val_score: 0.001096:  57%|#####7    | 4/7 [00:24<00:19,  6.41s/it]\u001b[32m[I 2021-10-03 12:46:30,892]\u001b[0m Trial 3 finished with value: 0.001817757082465981 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.001096440922652404.\u001b[0m\n",
            "feature_fraction, val_score: 0.001096:  57%|#####7    | 4/7 [00:24<00:19,  6.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00117304 + 0.000764567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "feature_fraction, val_score: 0.001096:  71%|#######1  | 5/7 [00:29<00:11,  5.79s/it]\u001b[32m[I 2021-10-03 12:46:35,593]\u001b[0m Trial 4 finished with value: 0.0011521482936611674 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.001096440922652404.\u001b[0m\n",
            "feature_fraction, val_score: 0.001096:  71%|#######1  | 5/7 [00:29<00:11,  5.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00162055 + 0.000905295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "feature_fraction, val_score: 0.001096:  86%|########5 | 6/7 [00:35<00:05,  5.91s/it]\u001b[32m[I 2021-10-03 12:46:41,734]\u001b[0m Trial 5 finished with value: 0.0014948618710372368 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.001096440922652404.\u001b[0m\n",
            "feature_fraction, val_score: 0.001096:  86%|########5 | 6/7 [00:35<00:05,  5.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00301344 + 0.0015852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "feature_fraction, val_score: 0.001096: 100%|##########| 7/7 [00:43<00:00,  6.47s/it]\u001b[32m[I 2021-10-03 12:46:49,370]\u001b[0m Trial 6 finished with value: 0.0028954767735275056 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.001096440922652404.\u001b[0m\n",
            "feature_fraction, val_score: 0.001096: 100%|##########| 7/7 [00:43<00:00,  6.17s/it]\n",
            "num_leaves, val_score: 0.001096:   0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00113775 + 0.000728627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001079:   5%|5         | 1/20 [00:13<04:10, 13.20s/it]\u001b[32m[I 2021-10-03 12:47:02,586]\u001b[0m Trial 7 finished with value: 0.0010792288936679322 and parameters: {'num_leaves': 181}. Best is trial 7 with value: 0.0010792288936679322.\u001b[0m\n",
            "num_leaves, val_score: 0.001079:   5%|5         | 1/20 [00:13<04:10, 13.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00113386 + 0.000723563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001072:  10%|#         | 2/20 [00:20<02:50,  9.47s/it]\u001b[32m[I 2021-10-03 12:47:09,460]\u001b[0m Trial 8 finished with value: 0.0010718471654581226 and parameters: {'num_leaves': 56}. Best is trial 8 with value: 0.0010718471654581226.\u001b[0m\n",
            "num_leaves, val_score: 0.001072:  10%|#         | 2/20 [00:20<02:50,  9.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00113548 + 0.000731237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001072:  15%|#5        | 3/20 [00:33<03:13, 11.37s/it]\u001b[32m[I 2021-10-03 12:47:23,079]\u001b[0m Trial 9 finished with value: 0.0010751908500232163 and parameters: {'num_leaves': 195}. Best is trial 8 with value: 0.0010718471654581226.\u001b[0m\n",
            "num_leaves, val_score: 0.001072:  15%|#5        | 3/20 [00:33<03:13, 11.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00288363 + 0.000458443\n",
            "[200]\tcv_agg's binary_logloss: 0.00153417 + 0.000747328\n",
            "[300]\tcv_agg's binary_logloss: 0.0014989 + 0.00104775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001072:  20%|##        | 4/20 [00:38<02:23,  8.96s/it]\u001b[32m[I 2021-10-03 12:47:28,343]\u001b[0m Trial 10 finished with value: 0.0014748656458386765 and parameters: {'num_leaves': 4}. Best is trial 8 with value: 0.0010718471654581226.\u001b[0m\n",
            "num_leaves, val_score: 0.001072:  20%|##        | 4/20 [00:38<02:23,  8.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.0011462 + 0.000733366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001072:  25%|##5       | 5/20 [00:46<02:06,  8.44s/it]\u001b[32m[I 2021-10-03 12:47:35,864]\u001b[0m Trial 11 finished with value: 0.0010774351678769565 and parameters: {'num_leaves': 68}. Best is trial 8 with value: 0.0010718471654581226.\u001b[0m\n",
            "num_leaves, val_score: 0.001072:  25%|##5       | 5/20 [00:46<02:06,  8.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00114117 + 0.00072977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001072:  30%|###       | 6/20 [01:00<02:26, 10.46s/it]\u001b[32m[I 2021-10-03 12:47:50,236]\u001b[0m Trial 12 finished with value: 0.001078693103599495 and parameters: {'num_leaves': 211}. Best is trial 8 with value: 0.0010718471654581226.\u001b[0m\n",
            "num_leaves, val_score: 0.001072:  30%|###       | 6/20 [01:00<02:26, 10.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00113634 + 0.000731399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001072:  35%|###5      | 7/20 [01:14<02:30, 11.57s/it]\u001b[32m[I 2021-10-03 12:48:04,093]\u001b[0m Trial 13 finished with value: 0.0010754013030444907 and parameters: {'num_leaves': 200}. Best is trial 8 with value: 0.0010718471654581226.\u001b[0m\n",
            "num_leaves, val_score: 0.001072:  35%|###5      | 7/20 [01:14<02:30, 11.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00114207 + 0.000729601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001072:  40%|####      | 8/20 [01:29<02:31, 12.59s/it]\u001b[32m[I 2021-10-03 12:48:18,867]\u001b[0m Trial 14 finished with value: 0.001079797256362387 and parameters: {'num_leaves': 222}. Best is trial 8 with value: 0.0010718471654581226.\u001b[0m\n",
            "num_leaves, val_score: 0.001072:  40%|####      | 8/20 [01:29<02:31, 12.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00113386 + 0.000723563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001072:  45%|####5     | 9/20 [01:36<01:58, 10.76s/it]\u001b[32m[I 2021-10-03 12:48:25,604]\u001b[0m Trial 15 finished with value: 0.0010718471654581226 and parameters: {'num_leaves': 56}. Best is trial 8 with value: 0.0010718471654581226.\u001b[0m\n",
            "num_leaves, val_score: 0.001072:  45%|####5     | 9/20 [01:36<01:58, 10.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00114586 + 0.000724871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001072:  50%|#####     | 10/20 [01:51<02:02, 12.26s/it]\u001b[32m[I 2021-10-03 12:48:41,243]\u001b[0m Trial 16 finished with value: 0.001089529035139591 and parameters: {'num_leaves': 248}. Best is trial 8 with value: 0.0010718471654581226.\u001b[0m\n",
            "num_leaves, val_score: 0.001072:  50%|#####     | 10/20 [01:51<02:02, 12.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.0011337 + 0.000715701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001072:  55%|#####5    | 11/20 [02:02<01:46, 11.79s/it]\u001b[32m[I 2021-10-03 12:48:51,945]\u001b[0m Trial 17 finished with value: 0.0010725966109516323 and parameters: {'num_leaves': 126}. Best is trial 8 with value: 0.0010718471654581226.\u001b[0m\n",
            "num_leaves, val_score: 0.001072:  55%|#####5    | 11/20 [02:02<01:46, 11.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00113386 + 0.000723563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001072:  60%|######    | 12/20 [02:09<01:22, 10.27s/it]\u001b[32m[I 2021-10-03 12:48:58,729]\u001b[0m Trial 18 finished with value: 0.0010718471654581226 and parameters: {'num_leaves': 56}. Best is trial 8 with value: 0.0010718471654581226.\u001b[0m\n",
            "num_leaves, val_score: 0.001072:  60%|######    | 12/20 [02:09<01:22, 10.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00114599 + 0.000753862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001072:  65%|######5   | 13/20 [02:17<01:07,  9.64s/it]\u001b[32m[I 2021-10-03 12:49:06,927]\u001b[0m Trial 19 finished with value: 0.0010785696895310591 and parameters: {'num_leaves': 78}. Best is trial 8 with value: 0.0010718471654581226.\u001b[0m\n",
            "num_leaves, val_score: 0.001072:  65%|######5   | 13/20 [02:17<01:07,  9.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00154185 + 0.000722785\n",
            "[200]\tcv_agg's binary_logloss: 0.00167612 + 0.00129868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001072:  70%|#######   | 14/20 [02:21<00:47,  8.00s/it]\u001b[32m[I 2021-10-03 12:49:11,129]\u001b[0m Trial 20 finished with value: 0.0014708324344317107 and parameters: {'num_leaves': 8}. Best is trial 8 with value: 0.0010718471654581226.\u001b[0m\n",
            "num_leaves, val_score: 0.001072:  70%|#######   | 14/20 [02:21<00:47,  8.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00112895 + 0.000700197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001072:  75%|#######5  | 15/20 [02:31<00:43,  8.61s/it]\u001b[32m[I 2021-10-03 12:49:21,150]\u001b[0m Trial 21 finished with value: 0.0010736084276400542 and parameters: {'num_leaves': 113}. Best is trial 8 with value: 0.0010718471654581226.\u001b[0m\n",
            "num_leaves, val_score: 0.001072:  75%|#######5  | 15/20 [02:31<00:43,  8.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.0011015 + 0.00071767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001042:  80%|########  | 16/20 [02:37<00:31,  7.85s/it]\u001b[32m[I 2021-10-03 12:49:27,250]\u001b[0m Trial 22 finished with value: 0.0010415601504281257 and parameters: {'num_leaves': 44}. Best is trial 22 with value: 0.0010415601504281257.\u001b[0m\n",
            "num_leaves, val_score: 0.001042:  80%|########  | 16/20 [02:37<00:31,  7.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00114568 + 0.00069247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001042:  85%|########5 | 17/20 [02:43<00:21,  7.08s/it]\u001b[32m[I 2021-10-03 12:49:32,519]\u001b[0m Trial 23 finished with value: 0.0010848941067442383 and parameters: {'num_leaves': 32}. Best is trial 22 with value: 0.0010415601504281257.\u001b[0m\n",
            "num_leaves, val_score: 0.001042:  85%|########5 | 17/20 [02:43<00:21,  7.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00113756 + 0.000728839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001042:  90%|######### | 18/20 [02:55<00:17,  8.61s/it]\u001b[32m[I 2021-10-03 12:49:44,709]\u001b[0m Trial 24 finished with value: 0.0010792270960840362 and parameters: {'num_leaves': 159}. Best is trial 22 with value: 0.0010415601504281257.\u001b[0m\n",
            "num_leaves, val_score: 0.001042:  90%|######### | 18/20 [02:55<00:17,  8.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00112515 + 0.000690739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001042:  95%|#########5| 19/20 [03:04<00:08,  8.89s/it]\u001b[32m[I 2021-10-03 12:49:54,247]\u001b[0m Trial 25 finished with value: 0.0010693183226000195 and parameters: {'num_leaves': 101}. Best is trial 22 with value: 0.0010415601504281257.\u001b[0m\n",
            "num_leaves, val_score: 0.001042:  95%|#########5| 19/20 [03:04<00:08,  8.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.0011384 + 0.000724852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "num_leaves, val_score: 0.001042: 100%|##########| 20/20 [03:14<00:00,  9.07s/it]\u001b[32m[I 2021-10-03 12:50:03,731]\u001b[0m Trial 26 finished with value: 0.0010836651341746908 and parameters: {'num_leaves': 100}. Best is trial 22 with value: 0.0010415601504281257.\u001b[0m\n",
            "num_leaves, val_score: 0.001042: 100%|##########| 20/20 [03:14<00:00,  9.72s/it]\n",
            "bagging, val_score: 0.001042:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.0012019 + 0.000779294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bagging, val_score: 0.001042:  10%|#         | 1/10 [00:06<00:58,  6.55s/it]\u001b[32m[I 2021-10-03 12:50:10,297]\u001b[0m Trial 27 finished with value: 0.001186359252911919 and parameters: {'bagging_fraction': 0.5458050094057939, 'bagging_freq': 5}. Best is trial 27 with value: 0.001186359252911919.\u001b[0m\n",
            "bagging, val_score: 0.001042:  10%|#         | 1/10 [00:06<00:58,  6.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00119522 + 0.000764833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bagging, val_score: 0.001042:  20%|##        | 2/10 [00:12<00:51,  6.38s/it]\u001b[32m[I 2021-10-03 12:50:16,551]\u001b[0m Trial 28 finished with value: 0.0011751125469915853 and parameters: {'bagging_fraction': 0.6053210551542785, 'bagging_freq': 1}. Best is trial 28 with value: 0.0011751125469915853.\u001b[0m\n",
            "bagging, val_score: 0.001042:  20%|##        | 2/10 [00:12<00:51,  6.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00116581 + 0.00065207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bagging, val_score: 0.001042:  30%|###       | 3/10 [00:19<00:46,  6.71s/it]\u001b[32m[I 2021-10-03 12:50:23,653]\u001b[0m Trial 29 finished with value: 0.0011294696198519472 and parameters: {'bagging_fraction': 0.8800876358105488, 'bagging_freq': 5}. Best is trial 29 with value: 0.0011294696198519472.\u001b[0m\n",
            "bagging, val_score: 0.001042:  30%|###       | 3/10 [00:19<00:46,  6.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.0011351 + 0.000831818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bagging, val_score: 0.001042:  40%|####      | 4/10 [00:26<00:41,  6.84s/it]\u001b[32m[I 2021-10-03 12:50:30,693]\u001b[0m Trial 30 finished with value: 0.001071709088198119 and parameters: {'bagging_fraction': 0.8439873030561655, 'bagging_freq': 7}. Best is trial 30 with value: 0.001071709088198119.\u001b[0m\n",
            "bagging, val_score: 0.001042:  40%|####      | 4/10 [00:26<00:41,  6.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00120181 + 0.000752734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bagging, val_score: 0.001042:  50%|#####     | 5/10 [00:33<00:33,  6.77s/it]\u001b[32m[I 2021-10-03 12:50:37,329]\u001b[0m Trial 31 finished with value: 0.0011617519855397676 and parameters: {'bagging_fraction': 0.5693257167893684, 'bagging_freq': 4}. Best is trial 30 with value: 0.001071709088198119.\u001b[0m\n",
            "bagging, val_score: 0.001042:  50%|#####     | 5/10 [00:33<00:33,  6.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.001172 + 0.000803806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bagging, val_score: 0.001042:  60%|######    | 6/10 [00:40<00:26,  6.72s/it]\u001b[32m[I 2021-10-03 12:50:43,946]\u001b[0m Trial 32 finished with value: 0.0011198766793870628 and parameters: {'bagging_fraction': 0.611761827026242, 'bagging_freq': 7}. Best is trial 30 with value: 0.001071709088198119.\u001b[0m\n",
            "bagging, val_score: 0.001042:  60%|######    | 6/10 [00:40<00:26,  6.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00125545 + 0.000745291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bagging, val_score: 0.001042:  70%|#######   | 7/10 [00:46<00:19,  6.58s/it]\u001b[32m[I 2021-10-03 12:50:50,259]\u001b[0m Trial 33 finished with value: 0.0012191324534606954 and parameters: {'bagging_fraction': 0.6391751796135415, 'bagging_freq': 1}. Best is trial 30 with value: 0.001071709088198119.\u001b[0m\n",
            "bagging, val_score: 0.001042:  70%|#######   | 7/10 [00:46<00:19,  6.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.0012615 + 0.000795213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bagging, val_score: 0.001042:  80%|########  | 8/10 [00:53<00:13,  6.62s/it]\u001b[32m[I 2021-10-03 12:50:56,958]\u001b[0m Trial 34 finished with value: 0.001208764843343302 and parameters: {'bagging_fraction': 0.5012352177926535, 'bagging_freq': 3}. Best is trial 30 with value: 0.001071709088198119.\u001b[0m\n",
            "bagging, val_score: 0.001042:  80%|########  | 8/10 [00:53<00:13,  6.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00132168 + 0.000852963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bagging, val_score: 0.001042:  90%|######### | 9/10 [00:59<00:06,  6.52s/it]\u001b[32m[I 2021-10-03 12:51:03,269]\u001b[0m Trial 35 finished with value: 0.0012842288287756047 and parameters: {'bagging_fraction': 0.4023979445035681, 'bagging_freq': 4}. Best is trial 30 with value: 0.001071709088198119.\u001b[0m\n",
            "bagging, val_score: 0.001042:  90%|######### | 9/10 [00:59<00:06,  6.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00127785 + 0.000786797\n",
            "[200]\tcv_agg's binary_logloss: 0.00136783 + 0.00135223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bagging, val_score: 0.001042: 100%|##########| 10/10 [01:07<00:00,  6.86s/it]\u001b[32m[I 2021-10-03 12:51:10,877]\u001b[0m Trial 36 finished with value: 0.0012446503411526184 and parameters: {'bagging_fraction': 0.5062662651667357, 'bagging_freq': 2}. Best is trial 30 with value: 0.001071709088198119.\u001b[0m\n",
            "bagging, val_score: 0.001042: 100%|##########| 10/10 [01:07<00:00,  6.71s/it]\n",
            "feature_fraction_stage2, val_score: 0.001042:   0%|          | 0/6 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00116712 + 0.00068418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "feature_fraction_stage2, val_score: 0.001042:  17%|#6        | 1/6 [00:05<00:28,  5.74s/it]\u001b[32m[I 2021-10-03 12:51:16,645]\u001b[0m Trial 37 finished with value: 0.0011108260899877428 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 37 with value: 0.0011108260899877428.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 0.001042:  17%|#6        | 1/6 [00:05<00:28,  5.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00111632 + 0.000773593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "feature_fraction_stage2, val_score: 0.001042:  33%|###3      | 2/6 [00:11<00:22,  5.62s/it]\u001b[32m[I 2021-10-03 12:51:22,182]\u001b[0m Trial 38 finished with value: 0.001085861884415899 and parameters: {'feature_fraction': 0.42}. Best is trial 38 with value: 0.001085861884415899.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 0.001042:  33%|###3      | 2/6 [00:11<00:22,  5.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.0011307 + 0.000694249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "feature_fraction_stage2, val_score: 0.001042:  50%|#####     | 3/6 [00:17<00:17,  5.78s/it]\u001b[32m[I 2021-10-03 12:51:28,155]\u001b[0m Trial 39 finished with value: 0.0010905882709173731 and parameters: {'feature_fraction': 0.484}. Best is trial 38 with value: 0.001085861884415899.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 0.001042:  50%|#####     | 3/6 [00:17<00:17,  5.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00126857 + 0.000748713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "feature_fraction_stage2, val_score: 0.001042:  67%|######6   | 4/6 [00:23<00:12,  6.02s/it]\u001b[32m[I 2021-10-03 12:51:34,534]\u001b[0m Trial 40 finished with value: 0.001194841393131098 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 38 with value: 0.001085861884415899.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 0.001042:  67%|######6   | 4/6 [00:23<00:12,  6.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00116879 + 0.000692724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "feature_fraction_stage2, val_score: 0.001042:  83%|########3 | 5/6 [00:29<00:06,  6.09s/it]\u001b[32m[I 2021-10-03 12:51:40,759]\u001b[0m Trial 41 finished with value: 0.0011031188266156108 and parameters: {'feature_fraction': 0.516}. Best is trial 38 with value: 0.001085861884415899.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 0.001042:  83%|########3 | 5/6 [00:29<00:06,  6.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00121444 + 0.000740575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "feature_fraction_stage2, val_score: 0.001042: 100%|##########| 6/6 [00:36<00:00,  6.23s/it]\u001b[32m[I 2021-10-03 12:51:47,246]\u001b[0m Trial 42 finished with value: 0.0011506638342663124 and parameters: {'feature_fraction': 0.58}. Best is trial 38 with value: 0.001085861884415899.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 0.001042: 100%|##########| 6/6 [00:36<00:00,  6.06s/it]\n",
            "regularization_factors, val_score: 0.001042:   0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00126849 + 0.000650873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001042:   5%|5         | 1/20 [00:03<01:11,  3.74s/it]\u001b[32m[I 2021-10-03 12:51:51,013]\u001b[0m Trial 43 finished with value: 0.0012187062553583572 and parameters: {'lambda_l1': 0.03495280182616009, 'lambda_l2': 0.0009095421717705857}. Best is trial 43 with value: 0.0012187062553583572.\u001b[0m\n",
            "regularization_factors, val_score: 0.001042:   5%|5         | 1/20 [00:03<01:11,  3.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00109856 + 0.000721025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001042:  10%|#         | 2/20 [00:09<01:24,  4.69s/it]\u001b[32m[I 2021-10-03 12:51:56,368]\u001b[0m Trial 44 finished with value: 0.0010491510184597258 and parameters: {'lambda_l1': 1.0779487127213605e-08, 'lambda_l2': 0.00011972692686353616}. Best is trial 44 with value: 0.0010491510184597258.\u001b[0m\n",
            "regularization_factors, val_score: 0.001042:  10%|#         | 2/20 [00:09<01:24,  4.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00124806 + 0.000655354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001042:  15%|#5        | 3/20 [00:13<01:14,  4.41s/it]\u001b[32m[I 2021-10-03 12:52:00,446]\u001b[0m Trial 45 finished with value: 0.001182611982702941 and parameters: {'lambda_l1': 0.012523052651953621, 'lambda_l2': 1.680334267722536e-07}. Best is trial 44 with value: 0.0010491510184597258.\u001b[0m\n",
            "regularization_factors, val_score: 0.001042:  15%|#5        | 3/20 [00:13<01:14,  4.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00187978 + 0.000536143\n",
            "[200]\tcv_agg's binary_logloss: 0.00159483 + 0.00061589\n",
            "[300]\tcv_agg's binary_logloss: 0.00157319 + 0.00062109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001042:  20%|##        | 4/20 [00:18<01:17,  4.83s/it]\u001b[32m[I 2021-10-03 12:52:05,914]\u001b[0m Trial 46 finished with value: 0.0015731179024777143 and parameters: {'lambda_l1': 0.6486217659039925, 'lambda_l2': 2.4166888826702504}. Best is trial 44 with value: 0.0010491510184597258.\u001b[0m\n",
            "regularization_factors, val_score: 0.001042:  20%|##        | 4/20 [00:18<01:17,  4.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00137116 + 0.000587363\n",
            "[200]\tcv_agg's binary_logloss: 0.00142085 + 0.000732158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001042:  25%|##5       | 5/20 [00:23<01:11,  4.75s/it]\u001b[32m[I 2021-10-03 12:52:10,526]\u001b[0m Trial 47 finished with value: 0.0013305558449917226 and parameters: {'lambda_l1': 0.023857127550577596, 'lambda_l2': 0.2060240301142392}. Best is trial 44 with value: 0.0010491510184597258.\u001b[0m\n",
            "regularization_factors, val_score: 0.001042:  25%|##5       | 5/20 [00:23<01:11,  4.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00115144 + 0.00074336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001042:  30%|###       | 6/20 [00:28<01:07,  4.82s/it]\u001b[32m[I 2021-10-03 12:52:15,504]\u001b[0m Trial 48 finished with value: 0.0010813878275948183 and parameters: {'lambda_l1': 0.0004225347473796565, 'lambda_l2': 0.0001900367020465478}. Best is trial 44 with value: 0.0010491510184597258.\u001b[0m\n",
            "regularization_factors, val_score: 0.001042:  30%|###       | 6/20 [00:28<01:07,  4.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00116813 + 0.000725218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001042:  35%|###5      | 7/20 [00:32<01:01,  4.73s/it]\u001b[32m[I 2021-10-03 12:52:20,040]\u001b[0m Trial 49 finished with value: 0.001103582945723549 and parameters: {'lambda_l1': 0.00288730219178297, 'lambda_l2': 9.798337012125863e-08}. Best is trial 44 with value: 0.0010491510184597258.\u001b[0m\n",
            "regularization_factors, val_score: 0.001042:  35%|###5      | 7/20 [00:32<01:01,  4.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00126377 + 0.000614797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001042:  40%|####      | 8/20 [00:37<00:55,  4.65s/it]\u001b[32m[I 2021-10-03 12:52:24,529]\u001b[0m Trial 50 finished with value: 0.0012177194340717713 and parameters: {'lambda_l1': 1.321480980100377e-06, 'lambda_l2': 0.06516823856249089}. Best is trial 44 with value: 0.0010491510184597258.\u001b[0m\n",
            "regularization_factors, val_score: 0.001042:  40%|####      | 8/20 [00:37<00:55,  4.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00125011 + 0.00069629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001042:  45%|####5     | 9/20 [00:41<00:51,  4.64s/it]\u001b[32m[I 2021-10-03 12:52:29,142]\u001b[0m Trial 51 finished with value: 0.001186631614586681 and parameters: {'lambda_l1': 1.298996837104101e-07, 'lambda_l2': 0.012613710111305782}. Best is trial 44 with value: 0.0010491510184597258.\u001b[0m\n",
            "regularization_factors, val_score: 0.001042:  45%|####5     | 9/20 [00:41<00:51,  4.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00156598 + 0.000605267\n",
            "[200]\tcv_agg's binary_logloss: 0.00147056 + 0.000733242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001042:  50%|#####     | 10/20 [00:47<00:48,  4.89s/it]\u001b[32m[I 2021-10-03 12:52:34,598]\u001b[0m Trial 52 finished with value: 0.0014602992112463162 and parameters: {'lambda_l1': 0.08579980267656188, 'lambda_l2': 0.9828519413002401}. Best is trial 44 with value: 0.0010491510184597258.\u001b[0m\n",
            "regularization_factors, val_score: 0.001042:  50%|#####     | 10/20 [00:47<00:48,  4.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00112888 + 0.000748799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001042:  55%|#####5    | 11/20 [00:53<00:46,  5.19s/it]\u001b[32m[I 2021-10-03 12:52:40,472]\u001b[0m Trial 53 finished with value: 0.0010603245141926575 and parameters: {'lambda_l1': 8.599146986197999e-06, 'lambda_l2': 1.0877957519968289e-05}. Best is trial 44 with value: 0.0010491510184597258.\u001b[0m\n",
            "regularization_factors, val_score: 0.001042:  55%|#####5    | 11/20 [00:53<00:46,  5.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00110727 + 0.000735452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001042:  60%|######    | 12/20 [01:00<00:46,  5.86s/it]\u001b[32m[I 2021-10-03 12:52:47,838]\u001b[0m Trial 54 finished with value: 0.0010530394541447463 and parameters: {'lambda_l1': 7.31979793561119e-06, 'lambda_l2': 9.345567042800555e-06}. Best is trial 44 with value: 0.0010491510184597258.\u001b[0m\n",
            "regularization_factors, val_score: 0.001042:  60%|######    | 12/20 [01:00<00:46,  5.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.0011052 + 0.0007387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001041:  65%|######5   | 13/20 [01:06<00:40,  5.81s/it]\u001b[32m[I 2021-10-03 12:52:53,558]\u001b[0m Trial 55 finished with value: 0.001041419863584947 and parameters: {'lambda_l1': 1.6055926159789167e-08, 'lambda_l2': 7.66432779011447e-06}. Best is trial 55 with value: 0.001041419863584947.\u001b[0m\n",
            "regularization_factors, val_score: 0.001041:  65%|######5   | 13/20 [01:06<00:40,  5.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00110661 + 0.000737069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001041:  70%|#######   | 14/20 [01:11<00:34,  5.77s/it]\u001b[32m[I 2021-10-03 12:52:59,247]\u001b[0m Trial 56 finished with value: 0.001041923116130438 and parameters: {'lambda_l1': 1.311311172082796e-08, 'lambda_l2': 6.7973666764831384e-06}. Best is trial 55 with value: 0.001041419863584947.\u001b[0m\n",
            "regularization_factors, val_score: 0.001041:  70%|#######   | 14/20 [01:11<00:34,  5.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00110834 + 0.000737419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001041:  75%|#######5  | 15/20 [01:17<00:28,  5.74s/it]\u001b[32m[I 2021-10-03 12:53:04,887]\u001b[0m Trial 57 finished with value: 0.0010440561725382851 and parameters: {'lambda_l1': 1.1176953799401568e-08, 'lambda_l2': 1.9113719480444704e-06}. Best is trial 55 with value: 0.001041419863584947.\u001b[0m\n",
            "regularization_factors, val_score: 0.001041:  75%|#######5  | 15/20 [01:17<00:28,  5.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00110273 + 0.000719752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001041:  80%|########  | 16/20 [01:23<00:22,  5.72s/it]\u001b[32m[I 2021-10-03 12:53:10,577]\u001b[0m Trial 58 finished with value: 0.0010420340050610543 and parameters: {'lambda_l1': 3.0941054260138706e-07, 'lambda_l2': 2.0613829962891183e-08}. Best is trial 55 with value: 0.001041419863584947.\u001b[0m\n",
            "regularization_factors, val_score: 0.001041:  80%|########  | 16/20 [01:23<00:22,  5.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00110303 + 0.000727457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001041:  85%|########5 | 17/20 [01:28<00:16,  5.64s/it]\u001b[32m[I 2021-10-03 12:53:16,032]\u001b[0m Trial 59 finished with value: 0.001043232205514987 and parameters: {'lambda_l1': 3.3836243302171005e-05, 'lambda_l2': 1.2340425200509268e-06}. Best is trial 55 with value: 0.001041419863584947.\u001b[0m\n",
            "regularization_factors, val_score: 0.001041:  85%|########5 | 17/20 [01:28<00:16,  5.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.0011907 + 0.000713323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001041:  90%|######### | 18/20 [01:33<00:10,  5.43s/it]\u001b[32m[I 2021-10-03 12:53:20,982]\u001b[0m Trial 60 finished with value: 0.0011171579588025082 and parameters: {'lambda_l1': 1.6684312457579728e-07, 'lambda_l2': 0.003182083070926493}. Best is trial 55 with value: 0.001041419863584947.\u001b[0m\n",
            "regularization_factors, val_score: 0.001041:  90%|######### | 18/20 [01:33<00:10,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00110029 + 0.000708132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001041:  95%|#########5| 19/20 [01:39<00:05,  5.46s/it]\u001b[32m[I 2021-10-03 12:53:26,493]\u001b[0m Trial 61 finished with value: 0.001046769368859494 and parameters: {'lambda_l1': 3.531759518985503e-08, 'lambda_l2': 3.404655979180511e-05}. Best is trial 55 with value: 0.001041419863584947.\u001b[0m\n",
            "regularization_factors, val_score: 0.001041:  95%|#########5| 19/20 [01:39<00:05,  5.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00111372 + 0.000736413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "regularization_factors, val_score: 0.001041: 100%|##########| 20/20 [01:44<00:00,  5.49s/it]\u001b[32m[I 2021-10-03 12:53:32,052]\u001b[0m Trial 62 finished with value: 0.001049051884431654 and parameters: {'lambda_l1': 1.2815795660917408e-06, 'lambda_l2': 1.0588318709437337e-06}. Best is trial 55 with value: 0.001041419863584947.\u001b[0m\n",
            "regularization_factors, val_score: 0.001041: 100%|##########| 20/20 [01:44<00:00,  5.24s/it]\n",
            "min_data_in_leaf, val_score: 0.001041:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00134931 + 0.000781195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "min_data_in_leaf, val_score: 0.001041:  20%|##        | 1/5 [00:05<00:22,  5.67s/it]\u001b[32m[I 2021-10-03 12:53:37,750]\u001b[0m Trial 63 finished with value: 0.0013128431124734285 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.0013128431124734285.\u001b[0m\n",
            "min_data_in_leaf, val_score: 0.001041:  20%|##        | 1/5 [00:05<00:22,  5.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\tcv_agg's binary_logloss: 0.00160833 + 0.00143442\n",
            "[100]\tcv_agg's binary_logloss: 0.00106903 + 0.000747342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "min_data_in_leaf, val_score: 0.001016:  40%|####      | 2/5 [00:11<00:16,  5.66s/it]\u001b[32m[I 2021-10-03 12:53:43,401]\u001b[0m Trial 64 finished with value: 0.0010158586989250126 and parameters: {'min_child_samples': 10}. Best is trial 64 with value: 0.0010158586989250126.\u001b[0m\n",
            "min_data_in_leaf, val_score: 0.001016:  40%|####      | 2/5 [00:11<00:16,  5.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.0011556 + 0.000640987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "min_data_in_leaf, val_score: 0.001016:  60%|######    | 3/5 [00:16<00:11,  5.61s/it]\u001b[32m[I 2021-10-03 12:53:48,951]\u001b[0m Trial 65 finished with value: 0.001111958510726194 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 0.0010158586989250126.\u001b[0m\n",
            "min_data_in_leaf, val_score: 0.001016:  60%|######    | 3/5 [00:16<00:11,  5.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00112084 + 0.000696845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "min_data_in_leaf, val_score: 0.001016:  80%|########  | 4/5 [00:22<00:05,  5.66s/it]\u001b[32m[I 2021-10-03 12:53:54,683]\u001b[0m Trial 66 finished with value: 0.0010612248810835084 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.0010158586989250126.\u001b[0m\n",
            "min_data_in_leaf, val_score: 0.001016:  80%|########  | 4/5 [00:22<00:05,  5.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\tcv_agg's binary_logloss: 0.00125815 + 0.000799472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "min_data_in_leaf, val_score: 0.001016: 100%|##########| 5/5 [00:28<00:00,  5.61s/it]\u001b[32m[I 2021-10-03 12:54:00,197]\u001b[0m Trial 67 finished with value: 0.0011982326767412844 and parameters: {'min_child_samples': 50}. Best is trial 64 with value: 0.0010158586989250126.\u001b[0m\n",
            "min_data_in_leaf, val_score: 0.001016: 100%|##########| 5/5 [00:28<00:00,  5.63s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4sok_LLrTkc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee6a0a6-4596-439e-f2e9-e92658f737e8"
      },
      "source": [
        "print(\"Best score:\", 1 - tuner.best_score)\n",
        "best_params = tuner.best_params\n",
        "print(\"Best params:\", best_params)\n",
        "print(\"  Params: \")\n",
        "for key, value in best_params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score: 0.9989841413010749\n",
            "Best params: {'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'feature_pre_filter': False, 'lambda_l1': 1.6055926159789167e-08, 'lambda_l2': 7.66432779011447e-06, 'num_leaves': 44, 'feature_fraction': 0.5, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 10}\n",
            "  Params: \n",
            "    objective: binary\n",
            "    metric: binary_logloss\n",
            "    verbosity: -1\n",
            "    boosting_type: gbdt\n",
            "    feature_pre_filter: False\n",
            "    lambda_l1: 1.6055926159789167e-08\n",
            "    lambda_l2: 7.66432779011447e-06\n",
            "    num_leaves: 44\n",
            "    feature_fraction: 0.5\n",
            "    bagging_fraction: 1.0\n",
            "    bagging_freq: 0\n",
            "    min_child_samples: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl0rDX8gIZMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa85112e-6b80-4e67-ef63-c8ba217833af"
      },
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 訓練データとテストデータを設定\n",
        "train_data = lgb.Dataset(X_train, label=y_train)\n",
        "test_data = lgb.Dataset(X_test, label=y_test)\n",
        "\n",
        "# ハイパーパラメータ探索で特定した値を設定(このパラメータは参考値)\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_logloss',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'lambda_l1': best_params['lambda_l1'],\n",
        "    'lambda_l2': best_params['lambda_l2'],\n",
        "    'num_leaves': best_params['num_leaves'],\n",
        "    'feature_fraction': best_params['feature_fraction'],\n",
        "    'bagging_fraction': best_params['bagging_fraction'],\n",
        "    'bagging_freq': best_params['bagging_freq'],\n",
        "    'min_child_samples': best_params['min_child_samples']\n",
        "}\n",
        "\n",
        "# 訓練の実施\n",
        "gbm = lgb.train(\n",
        "    params,\n",
        "    train_data,\n",
        "    num_boost_round=100,\n",
        "    verbose_eval=0,\n",
        ")\n",
        "\n",
        "# テスト用データを使って予測する\n",
        "preds = gbm.predict(X_test)\n",
        "# 戻り値は確率になっているので四捨五入する\n",
        "pred_labels_lgb = np.rint(preds)\n",
        "# 予測精度と混同行列の出力\n",
        "print(\"Accurary: {:.5f} %\".format(100 * accuracy_score(y_test, pred_labels_lgb)))\n",
        "print(confusion_matrix(y_test, pred_labels_lgb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accurary: 99.96684 %\n",
            "[[3847    0]\n",
            " [   2 2183]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3twSB7ys66-O"
      },
      "source": [
        "# 以下が７章の課題のコード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MuJyR8WwrZN",
        "outputId": "097cc6a0-a6ae-493e-d6ed-8478d2c33794"
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def objective(trial):\n",
        "    # 探索対象のハイパーパラメータを設定\n",
        "    eta =  trial.suggest_loguniform('eta', 1e-8, 1.0)\n",
        "    gamma = trial.suggest_loguniform('gamma', 1e-8, 1.0)\n",
        "    max_depth = trial.suggest_int('max_depth', 1, 20)\n",
        "    min_child_weight = trial.suggest_loguniform('min_child_weight', 1e-8, 1.0)\n",
        "    max_delta_step = trial.suggest_loguniform('max_delta_step', 1e-8, 1.0)\n",
        "    subsample = trial.suggest_uniform('subsample', 0.0, 1.0)\n",
        "    reg_lambda = trial.suggest_uniform('reg_lambda', 0.0, 1000.0)\n",
        "    reg_alpha = trial.suggest_uniform('reg_alpha', 0.0, 1000.0)\n",
        "\n",
        "\n",
        "    regr = xgb.XGBRegressor(\n",
        "        eta = eta,\n",
        "        gamma = gamma,\n",
        "        max_depth = max_depth,\n",
        "        min_child_weight = min_child_weight,\n",
        "        max_delta_step = max_delta_step,\n",
        "        subsample = subsample,\n",
        "        reg_lambda = reg_lambda,\n",
        "        reg_alpha = reg_alpha\n",
        "        )\n",
        "\n",
        "    regr.fit(X_train, y_train)\n",
        "\n",
        "    pred = regr.predict(X_test)\n",
        "    pred_labels = np.rint(preds)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, pred_labels)\n",
        "    return (1-accuracy)\n",
        "\n",
        "study = optuna.create_study()\n",
        "study.optimize(objective, n_trials=30)\n",
        "# ベストのパラメーターの出力\n",
        "print('Best params:', study.best_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:54:01,320]\u001b[0m A new study created in memory with name: no-name-0745d81f-4992-4ea7-86a1-aa920842f699\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:54:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:54:05,213]\u001b[0m Trial 0 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.23485225158730041, 'gamma': 0.21919050231670764, 'max_depth': 14, 'min_child_weight': 0.01515942380470655, 'max_delta_step': 0.386802781670313, 'subsample': 0.1703023157408503, 'reg_lambda': 550.4010320502056, 'reg_alpha': 158.9000644201991}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:54:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:54:06,165]\u001b[0m Trial 1 finished with value: 0.0003315649867373649 and parameters: {'eta': 4.555859530781887e-05, 'gamma': 6.684422233691827e-07, 'max_depth': 7, 'min_child_weight': 0.011376709637247897, 'max_delta_step': 1.0177562370919813e-08, 'subsample': 0.02885139719439811, 'reg_lambda': 353.6074184297265, 'reg_alpha': 754.5612681842466}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:54:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:54:12,717]\u001b[0m Trial 2 finished with value: 0.0003315649867373649 and parameters: {'eta': 4.505042478162852e-06, 'gamma': 1.307224263998537e-07, 'max_depth': 20, 'min_child_weight': 7.947508155814542e-05, 'max_delta_step': 3.709022797281267e-07, 'subsample': 0.4447390942492684, 'reg_lambda': 879.9243803182886, 'reg_alpha': 225.53893720462415}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:54:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:54:21,541]\u001b[0m Trial 3 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.0004619692643859808, 'gamma': 0.026977715779690752, 'max_depth': 15, 'min_child_weight': 0.07041326653228552, 'max_delta_step': 0.0002977968704363149, 'subsample': 0.6710765194960017, 'reg_lambda': 821.5216841207858, 'reg_alpha': 944.0919300871984}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:54:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:54:26,531]\u001b[0m Trial 4 finished with value: 0.0003315649867373649 and parameters: {'eta': 1.2221861177382003e-06, 'gamma': 1.016175212763662e-06, 'max_depth': 15, 'min_child_weight': 1.0203760676699044e-07, 'max_delta_step': 0.8297592471759907, 'subsample': 0.4028641545599425, 'reg_lambda': 531.7204910837675, 'reg_alpha': 439.36208596801055}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:54:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:54:37,313]\u001b[0m Trial 5 finished with value: 0.0003315649867373649 and parameters: {'eta': 3.816921630962475e-06, 'gamma': 0.01311677393136403, 'max_depth': 20, 'min_child_weight': 8.17792503920779e-06, 'max_delta_step': 2.008103530787669e-05, 'subsample': 0.9181638954607244, 'reg_lambda': 657.9932708866343, 'reg_alpha': 50.604912126080315}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:54:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:54:47,471]\u001b[0m Trial 6 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.003623943250650215, 'gamma': 1.4274550201258969e-05, 'max_depth': 8, 'min_child_weight': 0.004937776564228127, 'max_delta_step': 0.0017798831185896332, 'subsample': 0.8109268017900533, 'reg_lambda': 555.2129705530034, 'reg_alpha': 134.37325203808436}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:54:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:54:50,674]\u001b[0m Trial 7 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.0002670519224741577, 'gamma': 0.003797626790225328, 'max_depth': 7, 'min_child_weight': 3.142436366412262e-05, 'max_delta_step': 4.8480991479628915e-08, 'subsample': 0.2207924142763753, 'reg_lambda': 999.2608188401801, 'reg_alpha': 333.35820401288464}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:54:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:54:55,978]\u001b[0m Trial 8 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.0011785633612575329, 'gamma': 1.0544358145248492e-07, 'max_depth': 8, 'min_child_weight': 1.7027413951329726e-08, 'max_delta_step': 0.7809504097204132, 'subsample': 0.6230555418639269, 'reg_lambda': 144.84458053739445, 'reg_alpha': 450.59093171963104}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:54:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:55:03,976]\u001b[0m Trial 9 finished with value: 0.0003315649867373649 and parameters: {'eta': 8.670618362075798e-05, 'gamma': 0.00011754319863846288, 'max_depth': 6, 'min_child_weight': 2.528155118087902e-07, 'max_delta_step': 0.03314175326651144, 'subsample': 0.713625648915715, 'reg_lambda': 289.05395447191995, 'reg_alpha': 236.8825561061384}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:55:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:55:04,936]\u001b[0m Trial 10 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.5344085814474699, 'gamma': 0.6099739730683957, 'max_depth': 1, 'min_child_weight': 0.512945377520005, 'max_delta_step': 6.604196661791301e-06, 'subsample': 0.02864561011465827, 'reg_lambda': 108.29553988622473, 'reg_alpha': 650.7951422179021}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:55:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:55:05,850]\u001b[0m Trial 11 finished with value: 0.0003315649867373649 and parameters: {'eta': 3.823953529179017e-08, 'gamma': 8.2100880406128e-05, 'max_depth': 13, 'min_child_weight': 0.0032917632210200574, 'max_delta_step': 2.1470540755750817e-08, 'subsample': 0.01445289106037928, 'reg_lambda': 348.2344187884633, 'reg_alpha': 686.2109597133332}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:55:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:55:08,643]\u001b[0m Trial 12 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.9317661445822364, 'gamma': 2.2665549629910687e-06, 'max_depth': 3, 'min_child_weight': 0.0035372710601276306, 'max_delta_step': 0.009149693142233285, 'subsample': 0.22035392435370763, 'reg_lambda': 355.5780747968998, 'reg_alpha': 902.1579924845438}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:55:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:55:13,383]\u001b[0m Trial 13 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.022884270771428634, 'gamma': 0.38103628383289934, 'max_depth': 11, 'min_child_weight': 0.051913159475371076, 'max_delta_step': 1.625962362920636e-06, 'subsample': 0.24636793055855424, 'reg_lambda': 655.1920195128944, 'reg_alpha': 713.5457667069186}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:55:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:55:16,596]\u001b[0m Trial 14 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.041372348453366146, 'gamma': 0.0009588731157861067, 'max_depth': 17, 'min_child_weight': 0.0006676244696631194, 'max_delta_step': 8.279137229756216e-05, 'subsample': 0.1251562317927809, 'reg_lambda': 425.69437528241514, 'reg_alpha': 784.8792722516166}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:55:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:55:22,530]\u001b[0m Trial 15 finished with value: 0.0003315649867373649 and parameters: {'eta': 1.934753963477321e-07, 'gamma': 1.1586039494390724e-08, 'max_depth': 11, 'min_child_weight': 0.8000521988439753, 'max_delta_step': 0.03218925742318285, 'subsample': 0.35164698942639594, 'reg_lambda': 223.69400677667522, 'reg_alpha': 548.0822932882897}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:55:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:55:23,657]\u001b[0m Trial 16 finished with value: 0.0003315649867373649 and parameters: {'eta': 3.243856592197476e-05, 'gamma': 0.0003170019829864386, 'max_depth': 5, 'min_child_weight': 0.03965403591312815, 'max_delta_step': 4.147115451027056e-07, 'subsample': 0.09441048224341259, 'reg_lambda': 683.6924932890284, 'reg_alpha': 834.4550370382292}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:55:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:55:31,535]\u001b[0m Trial 17 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.06282005183635433, 'gamma': 0.0021843075939690726, 'max_depth': 17, 'min_child_weight': 0.0004285297335025808, 'max_delta_step': 0.00012308639633380413, 'subsample': 0.5515245756628533, 'reg_lambda': 468.44939780111855, 'reg_alpha': 564.1450419682313}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:55:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:55:36,145]\u001b[0m Trial 18 finished with value: 0.0003315649867373649 and parameters: {'eta': 1.1830726819577144e-08, 'gamma': 1.2360100253518202e-08, 'max_depth': 11, 'min_child_weight': 0.43979085571464027, 'max_delta_step': 0.0858109110123834, 'subsample': 0.3217359359732963, 'reg_lambda': 215.49158963145163, 'reg_alpha': 356.82948544740714}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:55:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:55:38,090]\u001b[0m Trial 19 finished with value: 0.0003315649867373649 and parameters: {'eta': 4.273881717738561e-05, 'gamma': 0.05203761749446846, 'max_depth': 2, 'min_child_weight': 0.05072158608843384, 'max_delta_step': 1.9094797820133396e-07, 'subsample': 0.15591595649717602, 'reg_lambda': 689.2348695690592, 'reg_alpha': 849.3296042810617}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:55:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:55:46,061]\u001b[0m Trial 20 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.07774025222706255, 'gamma': 0.12015895426479352, 'max_depth': 17, 'min_child_weight': 0.0003014365329604246, 'max_delta_step': 0.0010019956921984185, 'subsample': 0.5438131265999477, 'reg_lambda': 468.15771153899664, 'reg_alpha': 572.6947706265734}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:55:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:55:50,527]\u001b[0m Trial 21 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.009582473101868104, 'gamma': 0.0026851503652017055, 'max_depth': 13, 'min_child_weight': 3.882742521138563e-06, 'max_delta_step': 0.12701488199556482, 'subsample': 0.33213450266152045, 'reg_lambda': 19.22935795360641, 'reg_alpha': 343.1012570848244}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:55:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:55:57,661]\u001b[0m Trial 22 finished with value: 0.0003315649867373649 and parameters: {'eta': 3.362614673443367e-08, 'gamma': 0.09707011602256202, 'max_depth': 10, 'min_child_weight': 0.20672270136456908, 'max_delta_step': 0.2744738535499452, 'subsample': 0.27415657575207875, 'reg_lambda': 739.3597357541837, 'reg_alpha': 33.72718056528083}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:55:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:56:05,444]\u001b[0m Trial 23 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.1278267354953262, 'gamma': 0.08402369012465145, 'max_depth': 17, 'min_child_weight': 0.0005229298579611291, 'max_delta_step': 0.0018352097427300866, 'subsample': 0.521476656399098, 'reg_lambda': 583.614006369137, 'reg_alpha': 621.7719508591788}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:56:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:56:12,563]\u001b[0m Trial 24 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.006209878265824583, 'gamma': 0.008231298596184699, 'max_depth': 14, 'min_child_weight': 4.228259289948548e-06, 'max_delta_step': 0.003892225830293131, 'subsample': 0.44311986604628456, 'reg_lambda': 448.8984347716, 'reg_alpha': 301.7766007638857}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:56:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:56:20,700]\u001b[0m Trial 25 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.0089124750205587, 'gamma': 0.12636544975873515, 'max_depth': 13, 'min_child_weight': 1.042991802610194e-06, 'max_delta_step': 0.18453938432808387, 'subsample': 0.29538566310592523, 'reg_lambda': 795.7434856828652, 'reg_alpha': 43.05201987385671}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:56:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:56:28,015]\u001b[0m Trial 26 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.30815172949278813, 'gamma': 0.9900805792782007, 'max_depth': 18, 'min_child_weight': 0.18004726529433157, 'max_delta_step': 0.01992823535855419, 'subsample': 0.4916729300098682, 'reg_lambda': 599.596103767769, 'reg_alpha': 150.70149302984228}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:56:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:56:37,731]\u001b[0m Trial 27 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.1678091592565998, 'gamma': 0.0077410258442265215, 'max_depth': 15, 'min_child_weight': 2.0480575107715313e-05, 'max_delta_step': 0.004349583421197902, 'subsample': 0.7888601925290122, 'reg_lambda': 596.5730246333655, 'reg_alpha': 255.483870554711}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:56:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:56:48,964]\u001b[0m Trial 28 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.0043758462223211425, 'gamma': 0.24901564212646618, 'max_depth': 14, 'min_child_weight': 1.297020276410543e-06, 'max_delta_step': 0.24088338875756635, 'subsample': 0.4047223300903018, 'reg_lambda': 801.9631857442182, 'reg_alpha': 108.57344689604291}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:56:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-10-03 12:56:53,014]\u001b[0m Trial 29 finished with value: 0.0003315649867373649 and parameters: {'eta': 0.34680072946063256, 'gamma': 0.9078517361408194, 'max_depth': 19, 'min_child_weight': 0.018271377576020133, 'max_delta_step': 0.025046942311846242, 'subsample': 0.18305298390355476, 'reg_lambda': 963.1948580613326, 'reg_alpha': 179.8079222792345}. Best is trial 0 with value: 0.0003315649867373649.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'eta': 0.23485225158730041, 'gamma': 0.21919050231670764, 'max_depth': 14, 'min_child_weight': 0.01515942380470655, 'max_delta_step': 0.386802781670313, 'subsample': 0.1703023157408503, 'reg_lambda': 550.4010320502056, 'reg_alpha': 158.9000644201991}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cziOMZC6N2A",
        "outputId": "d943e910-3d98-41cf-8776-e9e8416d78ac"
      },
      "source": [
        "optimised_model = xgb.XGBRegressor(\n",
        "    eta = study.best_params['eta'],\n",
        "    gamma = study.best_params['gamma'],\n",
        "    max_depth = study.best_params['max_depth'],\n",
        "    min_child_weight = study.best_params['min_child_weight'],\n",
        "    max_delta_step = study.best_params['max_delta_step'],\n",
        "    subsample = study.best_params['subsample'],\n",
        "    reg_lambda = study.best_params['reg_lambda'],\n",
        "    reg_alpha = study.best_params['reg_alpha']\n",
        "    )\n",
        "\n",
        "optimised_model.fit(X_train, y_train)\n",
        "\n",
        "# テスト用データを使って予測する\n",
        "pred_labels_xgb = optimised_model.predict(X_test)\n",
        "# 返り値は確率になっているので四捨五入する\n",
        "pred_labels_xgb_round = np.rint(preds)\n",
        "# 予測精度と混同行列の出力\n",
        "print(\"Accurary: {:.5f} %\".format(\n",
        "    100 * accuracy_score(y_test, pred_labels_xgb_round)\n",
        "    )\n",
        ")\n",
        "print(confusion_matrix(y_test, pred_labels_xgb_round))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:56:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Accurary: 99.96684 %\n",
            "[[3847    0]\n",
            " [   2 2183]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu5M7Jwc5KIJ"
      },
      "source": [
        "preds_ans = pred_labels_lgb * 0.5 + pred_labels_xgb * 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emvQvHOO8f9B",
        "outputId": "e44cea87-6a8f-47e9-8e24-e4c01997a9d1"
      },
      "source": [
        "print(\"Accurary: {:.5f} %\".format(\n",
        "    100 * accuracy_score(y_test, np.rint(preds_ans))\n",
        "    )\n",
        ")\n",
        "print(confusion_matrix(y_test, np.rint(preds_ans)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accurary: 99.96684 %\n",
            "[[3847    0]\n",
            " [   2 2183]]\n"
          ]
        }
      ]
    }
  ]
}